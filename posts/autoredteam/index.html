<!DOCTYPE html><html lang="en"> <head><!-- Global Metadata --><meta charset="utf-8"><meta name="viewport" content="width=device-width,initial-scale=1"><link rel="icon" type="image/svg+xml" href="https://raw.githubusercontent.com/aurora-lm/aurora-lm.github.io/main/assets/images/about_us/aurora-lm-logo.png"><meta name="generator" content="Astro v5.1.1"><!-- Canonical URL --><link rel="canonical" href="https://aurora-lm.github.io/posts/autoredteam/"><!-- Sitemap --><link rel="sitemap" href="/sitemap-index.xml"><!-- Primary Meta Tags --><title>AutoRedTeam: Policy-Based Multimodal Multilingual Data Generation</title><meta name="title" content="AutoRedTeam: Policy-Based Multimodal Multilingual Data Generation"><meta name="description" content="We introduce a novel pipeline for generating instructions to AutoRedteam a model for a specific policy, focusing on EU AI Act Annex III regulations for high-risk AI."><!-- Open Graph / Facebook --><meta property="og:type" content="website"><meta property="og:url" content="https://aurora-lm.github.io/posts/autoredteam/"><meta property="og:title" content="AutoRedTeam: Policy-Based Multimodal Multilingual Data Generation"><meta property="og:description" content="We introduce a novel pipeline for generating instructions to AutoRedteam a model for a specific policy, focusing on EU AI Act Annex III regulations for high-risk AI."><meta property="og:image" content="https://aurora-lm.github.io/blog-placeholder-1.avif"><!-- Twitter --><meta property="twitter:card" content="summary_large_image"><meta property="twitter:url" content="https://aurora-lm.github.io/posts/autoredteam/"><meta property="twitter:title" content="AutoRedTeam: Policy-Based Multimodal Multilingual Data Generation"><meta property="twitter:description" content="We introduce a novel pipeline for generating instructions to AutoRedteam a model for a specific policy, focusing on EU AI Act Annex III regulations for high-risk AI."><meta property="twitter:image" content="https://aurora-lm.github.io/blog-placeholder-1.avif"><!-- Preline CSS --><script type="module" src="/_astro/BaseHead.astro_astro_type_script_index_0_lang.BtT675nX.js"></script><link rel="stylesheet" href="/_astro/_page_.a1X1-JMm.css">
<style>[data-astro-image]{width:100%;height:auto;-o-object-fit:var(--fit);object-fit:var(--fit);-o-object-position:var(--pos);object-position:var(--pos);aspect-ratio:var(--w) / var(--h)}[data-astro-image=responsive]{max-width:calc(var(--w) * 1px);max-height:calc(var(--h) * 1px)}[data-astro-image=fixed]{width:calc(var(--w) * 1px);height:calc(var(--h) * 1px)}
</style><script type="module" src="/_astro/page.DTIbhfSr.js"></script>
<script>!(function(w,p,f,c){if(!window.crossOriginIsolated && !navigator.serviceWorker) return;c=w[p]=Object.assign(w[p]||{},{"lib":"/~partytown/","debug":false});c[f]=(c[f]||[]).concat(["dataLayer.push"])})(window,'partytown','forward');/* Partytown 0.10.2 - MIT builder.io */
const t={preserveBehavior:!1},e=e=>{if("string"==typeof e)return[e,t];const[n,r=t]=e;return[n,{...t,...r}]},n=Object.freeze((t=>{const e=new Set;let n=[];do{Object.getOwnPropertyNames(n).forEach((t=>{"function"==typeof n[t]&&e.add(t)}))}while((n=Object.getPrototypeOf(n))!==Object.prototype);return Array.from(e)})());!function(t,r,o,i,a,s,c,d,l,p,u=t,f){function h(){f||(f=1,"/"==(c=(s.lib||"/~partytown/")+(s.debug?"debug/":""))[0]&&(l=r.querySelectorAll('script[type="text/partytown"]'),i!=t?i.dispatchEvent(new CustomEvent("pt1",{detail:t})):(d=setTimeout(v,1e4),r.addEventListener("pt0",w),a?y(1):o.serviceWorker?o.serviceWorker.register(c+(s.swPath||"partytown-sw.js"),{scope:c}).then((function(t){t.active?y():t.installing&&t.installing.addEventListener("statechange",(function(t){"activated"==t.target.state&&y()}))}),console.error):v())))}function y(e){p=r.createElement(e?"script":"iframe"),t._pttab=Date.now(),e||(p.style.display="block",p.style.width="0",p.style.height="0",p.style.border="0",p.style.visibility="hidden",p.setAttribute("aria-hidden",!0)),p.src=c+"partytown-"+(e?"atomics.js?v=0.10.2":"sandbox-sw.html?"+t._pttab),r.querySelector(s.sandboxParent||"body").appendChild(p)}function v(n,o){for(w(),i==t&&(s.forward||[]).map((function(n){const[r]=e(n);delete t[r.split(".")[0]]})),n=0;n<l.length;n++)(o=r.createElement("script")).innerHTML=l[n].innerHTML,o.nonce=s.nonce,r.head.appendChild(o);p&&p.parentNode.removeChild(p)}function w(){clearTimeout(d)}s=t.partytown||{},i==t&&(s.forward||[]).map((function(r){const[o,{preserveBehavior:i}]=e(r);u=t,o.split(".").map((function(e,r,o){var a;u=u[o[r]]=r+1<o.length?u[o[r]]||(a=o[r+1],n.includes(a)?[]:{}):(()=>{let e=null;if(i){const{methodOrProperty:n,thisObject:r}=((t,e)=>{let n=t;for(let t=0;t<e.length-1;t+=1)n=n[e[t]];return{thisObject:n,methodOrProperty:e.length>0?n[e[e.length-1]]:void 0}})(t,o);"function"==typeof n&&(e=(...t)=>n.apply(r,...t))}return function(){let n;return e&&(n=e(arguments)),(t._ptf=t._ptf||[]).push(o,arguments),n}})()}))})),"complete"==r.readyState?h():(t.addEventListener("DOMContentLoaded",h),t.addEventListener("load",h))}(window,document,navigator,top,window.crossOriginIsolated);;(e=>{e.addEventListener("astro:before-swap",e=>{let r=document.body.querySelector("iframe[src*='/~partytown/']");if(r)e.newDocument.body.append(r)})})(document);</script></head> <body class="flex flex-col min-h-screen mx-auto max-w-6xl px-4 dark:prose-invert sm:px-6 lg:px-8 dark:bg-neutral-900"> <header class="flex flex-wrap md:justify-start md:flex-nowrap z-50 w-full py-7"> <nav class="relative max-w-7xl w-full flex flex-wrap md:grid md:grid-cols-12 basis-full items-center px-4 mx-auto" aria-label="Global"> <div class="md:col-span-3"> <a class="flex-none text-xl font-semibold text-neutral-900 hover:text-neutral-600 dark:text-neutral-400 dark:hover:text-neutral-200" href="/" aria-label="Astroverse"> Aurora-M2 </a> </div> <div class="flex items-center gap-x-2 ms-auto py-1 md:ps-6 md:order-3 md:col-span-3"> <button type="button" class="py-2 px-3 inline-flex items-center gap-x-2 text-sm font-medium rounded-xl border border-transparent text-black hover:bg-neutral-100 dark:text-white dark:hover:bg-neutral-700 transition disabled:opacity-50 disabled:pointer-events-none" onclick="window.location.href='/search/'"> <svg width="1em" height="1em" class="icon-base" data-icon="tabler:search">   <symbol id="ai:tabler:search" viewBox="0 0 24 24"><path fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M3 10a7 7 0 1 0 14 0a7 7 0 1 0-14 0m18 11l-6-6"/></symbol><use href="#ai:tabler:search"></use>  </svg> </button> <button type="button" class="hs-dark-mode hs-dark-mode-active:hidden inline-flex items-center gap-x-2 py-2 px-3 rounded-full text-sm text-black hover:bg-white/20" data-hs-theme-click-value="dark"> <svg width="1em" height="1em" class="icon-base" data-icon="tabler:sun-filled">   <symbol id="ai:tabler:sun-filled" viewBox="0 0 24 24"><path fill="currentColor" d="M12 19a1 1 0 0 1 .993.883L13 20v1a1 1 0 0 1-1.993.117L11 21v-1a1 1 0 0 1 1-1m6.313-2.09l.094.083l.7.7a1 1 0 0 1-1.32 1.497l-.094-.083l-.7-.7a1 1 0 0 1 1.218-1.567zm-11.306.083a1 1 0 0 1 .083 1.32l-.083.094l-.7.7a1 1 0 0 1-1.497-1.32l.083-.094l.7-.7a1 1 0 0 1 1.414 0M4 11a1 1 0 0 1 .117 1.993L4 13H3a1 1 0 0 1-.117-1.993L3 11zm17 0a1 1 0 0 1 .117 1.993L21 13h-1a1 1 0 0 1-.117-1.993L20 11zM6.213 4.81l.094.083l.7.7a1 1 0 0 1-1.32 1.497l-.094-.083l-.7-.7A1 1 0 0 1 6.11 4.74zm12.894.083a1 1 0 0 1 .083 1.32l-.083.094l-.7.7a1 1 0 0 1-1.497-1.32l.083-.094l.7-.7a1 1 0 0 1 1.414 0M12 2a1 1 0 0 1 .993.883L13 3v1a1 1 0 0 1-1.993.117L11 4V3a1 1 0 0 1 1-1m0 5a5 5 0 1 1-4.995 5.217L7 12l.005-.217A5 5 0 0 1 12 7"/></symbol><use href="#ai:tabler:sun-filled"></use>  </svg> </button> <button type="button" class="hs-dark-mode hs-dark-mode-active:inline-flex hidden items-center gap-x-2 py-2 px-3 rounded-full text-sm text-white hover:bg-white/20" data-hs-theme-click-value="light"> <svg width="1em" height="1em" class="icon-base" data-icon="tabler:moon-filled">   <symbol id="ai:tabler:moon-filled" viewBox="0 0 24 24"><path fill="currentColor" d="M12 1.992a10 10 0 1 0 9.236 13.838c.341-.82-.476-1.644-1.298-1.31a6.5 6.5 0 0 1-6.864-10.787l.077-.08c.551-.63.113-1.653-.758-1.653h-.266l-.068-.006z"/></symbol><use href="#ai:tabler:moon-filled"></use>  </svg> </button> <div class="md:hidden"> <button type="button" class="hs-collapse-toggle size-[38px] flex justify-center items-center text-sm font-semibold rounded-xl text-black hover:bg-neutral-100 disabled:opacity-50 disabled:pointer-events-none dark:text-white dark:hover:bg-neutral-700" data-hs-collapse="#navbar-collapse-with-animation" aria-controls="navbar-collapse-with-animation" aria-label="Toggle navigation"> <svg width="1em" height="1em" class="hs-collapse-open:hidden flex-shrink-0 size-4" data-icon="tabler:menu-2">   <symbol id="ai:tabler:menu-2" viewBox="0 0 24 24"><path fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M4 6h16M4 12h16M4 18h16"/></symbol><use href="#ai:tabler:menu-2"></use>  </svg> <svg width="1em" height="1em" class="hs-collapse-open:block hidden flex-shrink-0 size-4" data-icon="tabler:menu-order">   <symbol id="ai:tabler:menu-order" viewBox="0 0 24 24"><path fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M4 10h16M4 14h16M9 18l3 3l3-3M9 6l3-3l3 3"/></symbol><use href="#ai:tabler:menu-order"></use>  </svg> </button> </div> </div> <div id="navbar-collapse-with-animation" class="hs-collapse hidden overflow-hidden transition-all duration-300 basis-full grow md:block md:w-auto md:basis-auto md:order-2 md:col-span-6"> <div class="flex flex-col gap-y-4 gap-x-0 mt-5 md:flex-row md:justify-center md:items-center md:gap-y-0 md:gap-x-7 md:mt-0"> <a href="/posts/about-us/" class="px-4 py-3 font-medium text-neutral-900 hover:text-neutral-600 dark:text-neutral-400 dark:hover:text-neutral-200"> About Us </a><a href="/category/One/1/" class="px-4 py-3 font-medium text-neutral-900 hover:text-neutral-600 dark:text-neutral-400 dark:hover:text-neutral-200"> Blog Posts </a><a href="/tags/" class="px-4 py-3 font-medium text-neutral-900 hover:text-neutral-600 dark:text-neutral-400 dark:hover:text-neutral-200"> Sort by Tags </a> </div> </div> </nav> </header> <main class="flex-grow">  <main> <article class="prose mx-auto dark:prose-invert"> <div class="prose-h1 text-center"> <h1>AutoRedTeam: Policy-Based Multimodal Multilingual Data Generation</h1> </div> <div> <picture> <source srcset="https://raw.githubusercontent.com/aurora-lm/aurora-lm.github.io/main/assets/images/autoredteam/EU_AI_Act.png 392w, https://raw.githubusercontent.com/aurora-lm/aurora-lm.github.io/main/assets/images/autoredteam/EU_AI_Act.png 700w, https://raw.githubusercontent.com/aurora-lm/aurora-lm.github.io/main/assets/images/autoredteam/EU_AI_Act.png 980w, https://raw.githubusercontent.com/aurora-lm/aurora-lm.github.io/main/assets/images/autoredteam/EU_AI_Act.png 1960w" type="image/avif" sizes="(max-width: 360px) 392px, 
           (max-width: 720px) 700px, 
           (max-width: 1600px) 980px, 
           1960px">  <img src="https://raw.githubusercontent.com/aurora-lm/aurora-lm.github.io/main/assets/images/autoredteam/EU_AI_Act.png" srcset="https://raw.githubusercontent.com/aurora-lm/aurora-lm.github.io/main/assets/images/autoredteam/EU_AI_Act.png 392w, https://raw.githubusercontent.com/aurora-lm/aurora-lm.github.io/main/assets/images/autoredteam/EU_AI_Act.png 700w, https://raw.githubusercontent.com/aurora-lm/aurora-lm.github.io/main/assets/images/autoredteam/EU_AI_Act.png 980w, https://raw.githubusercontent.com/aurora-lm/aurora-lm.github.io/main/assets/images/autoredteam/EU_AI_Act.png 1960w" alt="Blue Bird Flash" sizes="(max-width: 360px) 392px, 
           (max-width: 720px) 700px, 
           (max-width: 1600px) 980px, 
           1960px" width="1024" height="1024" loading="lazy" decoding="async" class="mx-auto w-full max-w-full rounded-lg"> </picture> </div> <div> <p><strong>By: <a href="https://www.linkedin.com/in/huu-ai-machine-learning/">Huu Nguyen</a>, <a href="hraj172.github.io">Harsh Raj</a>, <a href="https://www.ml.informatik.tu-darmstadt.de/people/ffriedrich/index.html">Felix Friedrich</a>, <a href="https://www.linkedin.com/in/ken-tsui-06889b29/?originalSubdomain=uk">Ken Tsui</a>— Apr 24, 2025</strong></p>
<div align="center">
<p><strong>Huggingface:</strong> <a href="https://huggingface.co/datasets/ontocord/aurora-m2-autoredteam" style="color: #1f6feb;" target="_blank"><strong>AutoRedTeam</strong></a></p>
</div>
<p>This blog inroduces our pipeline for generating novel instructions to Redeam a model for a specific policy. In particular, we focus on the <a href="https://artificialintelligenceact.eu/annex/3/">EU AI Act Annex III</a>, which outlines rules and regulations for the use of AI systems in high-risk environments.</p>
<p>Some example rules from this section include:</p>
<ul>
<li>“AI systems shall not be intended for the recruitment or selection of natural persons, in particular to place targeted job advertisements, to analyse and filter job applications, and to evaluate candidates”</li>
<li>“AI systems must not be designed for use by public authorities or EU institutions as polygraphs or similar tools.”</li>
</ul>
<p>Training models to align with such specific and nuanced policies requires large volumes of carefully curated data. Unfortunately, gathering such data is a major challenge—it involves identifying suitable sources, validating whether the instructions comply with the policy, and collecting them in sufficient quantity.</p>
<p>Another major issue is diversity. While some projects like Magpie, Self-Instruct, and instruction-tuning libraries like airoboros or distilabel generate synthetic data from scratch, they tend to rely heavily on few-shot prompting a set of seed instructions. This approach hinges on having a well-balanced, diverse set of seed instructions to start with—something that’s hard to come by.</p>
<p>If the initial seed data lacks diversity, the model may start collapsing after a few rounds of generation, producing narrow or repetitive outputs. The challenge increases when you consider Multimodal LLMs. It’s already difficult enough to generate policy-aligned text data—now imagine doing the same for images, videos, and audio. The scale and complexity of that task are enormous.</p>
<h2 id="method">Method</h2>
<figure>
  <img src="https://raw.githubusercontent.com/aurora-lm/aurora-lm.github.io/main/assets/images/autoredteam/autoredteam-flow.png" alt="The process of Ontology based AutoRedTeaming">
  <figcaption>The process of Ontology-based <em>AutoRedTeaming</em>.</figcaption>
</figure>
<p>Just to reiterate on our goal for this project: goal of the AuroraM2 project is to create multimodal, multilingual, high permanent model which is aligned with the EU Ai Act. We introduce the real Autoredteam: A novel technique introduced for training AuroraM2, a scalable and automated instruction generation framework designed to ensure AI compliance with regulatory standards such as the EU AI Act specifically the EU AI Act High Risk Categories from Annexe III.</p>
<p>Unlike traditional human-curated datasets, AutoRedteam systematically generates, evaluates, and refines instruction-response pairs, improving both model helpfulness and safety in a controlled and targeted manner. Key Features of AutoRedteam include Ontology-Driven Instruction Generation, where a word-object ontology is used to create structured seed instructions covering explanations, reasoning tasks, creative prompts, adversarial cases, and ethical dilemmas, with contextual snippets integrated to enhance realism.</p>
<p>This ontology-based approach systematically permutes diverse instructions to create seeds catering to various fields such as science, mathematics, sports, and healthcare, allowing precise control over different instruction types. Systematic Upsampling enhances adaptability through linguistic variations, multilingual translations, adversarial modifications, and persona shifts, ensuring diverse and unique instructions that align the model with realistic knowledge representation.</p>
<p>Jailbreak Upsampling for Adversarial Testing applies jailbreak prompts to 30% of instructions and responses to assess robustness, inspired by the Tree of Attacks, upsampling them into long jailbreaking forms. Response Generation and Policy Alignment ensures model responses adhere to AI safety and ethical standards, with a special focus on high-risk categories defined in Annex III of the EU AI Act.</p>
<p>Reasoning traces are introduced to ensure that models do not directly refuse instructions but instead engage in reasoning before refusal, preventing over-refusal behavior in AI models. Compliance is assessed using the LlamaGuard Evaluator, incorporating self-consistency testing, comparative judgment by a stronger teacher LLM, and response reinforcement. Iterative Correction and Reinforcement refines unsafe or unhelpful responses through adversarial retesting, with approximately 30% of responses failing initial safety checks—20% requiring safer rewrites and 10% exhibiting contradictions that must be resolved.</p>
<p>Now, let’s walk through each part of the Autoredteam pipeline in detail.</p>
<h2 id="ontology-driven-instruction-generation">Ontology-driven Instruction Generation</h2>
<h3 id="ontology">Ontology</h3>
<p>In the Autoredteam pipeline, the ontology acts as a structured knowledge representation system. It organizes concepts and their relationships to help generate diverse and targeted instructions.</p>
<p>The ontology consists of two main components:</p>
<ul>
<li>Verb templates – Different types of actions or operations</li>
<li>Object templates – Different types of entities that can be acted upon</li>
</ul>
<p>Together, these form a verb-object ontology, systematically mapping relationships between actions (verbs) and entities (objects) to create meaningful, diverse instructions.</p>
<h3 id="how-are-ontology-based-instructions-created">How Are Ontology-Based Instructions Created?</h3>
<h4 id="1-predefined-template-dictionaries">1. Predefined Template Dictionaries</h4>
<p>Ontology generation starts with predefined verb-object mappings that serve as the foundation for the knowledge structure. This is similar to WordNet, where entities are mapped to related entities based on linguistic relationships.</p>
<p>We define multiple object and verb categories that capture different types of concepts. For example:</p>
<ul>
<li>Object category: “Job skills” might include items like critical thinking skills, problem-solving skills</li>
<li>Verb category: “Harmful actions related to disease” might include verbs like spreading, culturing, infecting others with</li>
</ul>
<p>These mappings form a structured taxonomy that organizes concepts by type and provides the raw materials for generating rich, policy-aware instructions.</p>
<h4 id="2-semantic-matching-rules">2. Semantic Matching Rules</h4>
<p>To ensure that only meaningful combinations of verbs and objects are used, we apply several semantic filtering rules:</p>
<ul>
<li>Extract significant words from both the verb and object types (filtering out stopwords and generic terms)</li>
<li>Handle special cases (e.g., if the object includes “children,” “figures,” or “adults,” the broader term “people” may be added)</li>
<li>Check for overlap between filtered verb and object keywords to assess compatibility</li>
</ul>
<p>Example:
If the object type is science_subjects and the verb type is communication_with_science, filtered keywords might be:</p>
<ul>
<li>Object words: [“science”, “subjects”]</li>
<li>Verb words: [“communication”, “science”]</li>
</ul>
<p>Since “science” appears in both, the pair is deemed compatible.</p>
<h4 id="3-instruction-creation">3. Instruction Creation</h4>
<p>This is the core of the ontology system. Once verb-object compatibility is established, verbs and objects are selected from their respective templates and combined to form instructions.</p>
<p>We use a variety of instruction formats and templates, and often upsample combinations using conditional clauses. For instance, if the verb type is communication and the object type is science, possible instructions include:</p>
<ul>
<li>“Explain quantum physics.”</li>
<li>“Describe scientific principles.”</li>
</ul>
<p>We also generate diverse formats—such as multiple-choice questions, different instruction tones, and contextual variants—to improve the robustness and coverage of the instruction set. All the upsampling at this stage is done by sentence structure modifications.</p>
<h4 id="4-context-integration">4. Context Integration</h4>
<p>If relevant context is available—or if a user provides specific context—it is integrated into the instruction.</p>
<p>This involves cleaning existing textual data and breaking it into usable chunks, which are then prepended or appended to the instruction. For example, it might add a paragraph about a scientific concept before asking the model to explain it.</p>
<p>Predefined Template Dictionaries - The Autoredteam ontology creation begins with predefined verb object mappings that form the foundation of the knowledge structure. Typically this is similar to wordnet which maps entities to related entities w.r.t. language structure. We define multiple object and verb mappings that organize different types of entities and actions. For example: categories for skills contain job skills like “critical thinking skills”, “problem solving skills” or verb “harmful actions related to disease” contains actions like “spreading”, “culturing”, “infecting others with”. These mappings create a structured taxonomy where concepts are organized by type, providing the raw materials for generating diverse instructions.</p>
<p>Semantic Matching Rules - We ensure that only meaningful combinations of verbs and objects are used. Like:</p>
<ul>
<li>Extracts meaningful words from both the verb type and object type (filtering out stopwords and common terms)</li>
<li>Handle special cases (e.g., if “children,” “figures,” or “adults” appear, add “people” to the object list)</li>
<li>Checks if any object type word appears within the verb type (indicating compatibility).</li>
</ul>
<p>For example, If object type is “science_subjects” and verb_type is “communication_with_science”, the filtered object words might be [“science”, “subjects”] and the filtered verb words might be [“communication”, “science”]. Since “science” appears in both lists, these would be deemed compatible.</p>
<p>Instruction Creation - It is the heart of the Autoredteam’s ontology system. This process combines verb types (actions) and object types (subjects) to ensure both semantic coherence. First it, checks that the verb type and object type are compatible then selects verbs and objects from respective predefined templates and then combine them by choosing from a varied list of instruction types and formats. It is upsamping the verb and object pairs using conditional clauses and some predefined templates. For example, if the verb type is “communication” and the object type is “science”, it might generate instructions like “Explain quantum physics” or “Describe scientific principles.”, We create varied types of formats for instructions like instructions with choosing options, or instructions in different tones.</p>
<p>Context Integration - If we find relevant context to a created instruction or if the user inputs a relevant context for the created instruction it It takes existing text data, cleans it, and breaks it into chunks that can be used as contextual information. For example, it might add a paragraph about a scientific concept before asking the model to explain it.</p>
<h2 id="systematic-upsampling">Systematic Upsampling</h2>
<p>After creating basic instructions using the ontology-driven approach, the Autoredteam pipeline uses upsampling to increase the diversity of the dataset. This process transforms basic instructions into more varied and adversarial forms that better test the model. We use several techniques for this:</p>
<h3 id="linguistic-variation">Linguistic Variation</h3>
<p>The upsampling process begins with basic syntactic transformations that restructure sentences while preserving meaning. For example, a sentence like “Explain quantum mechanics” might be rearranged to “Quantum mechanics needs explanation for a beginner.” We do this through operations like splitting sentences at punctuation points and rearranging clauses, for example:</p>
<ul>
<li>Sentence reordering: Breaking sentences at periods, commas, or specific phrases (like “in”, “on”, “with”) and reconstructing them with altered order</li>
<li>Synonym substitution: Replacing words with synonyms to create linguistic diversity</li>
<li>Structure transformation: Converting statements to questions and vice versa</li>
</ul>
<h3 id="stylistic-modifications">Stylistic Modifications</h3>
<p>We introduce other common modification techniques often used in dataset creation works:</p>
<ul>
<li>Style adaptation: Instructions are rewritten according to specific revision types (like use simple sentence structure, use child-like language) that alter tone, complexity, or framing.</li>
<li>Persona transformation: The code uses a diverse set of personas similar to this work to rewrite instructions from different viewpoints, which helps test the model’s ability to handle varied user intents and styles</li>
</ul>
<h3 id="multilingual-expansion">Multilingual Expansion</h3>
<p>For robustness, a portion of instructions are translated into different languages. We target languages and append language-specific instructions like “Respond in Hindi” to ensure cross-lingual evaluation.</p>
<h3 id="jailbreak-testing">Jailbreak Testing</h3>
<p>To evaluate model safety boundaries, the upsampling process includes dedicated jailbreak transformations. We use adversarial techniques adapted from the work named Tree of Attacks. For instance, a basic instruction like “Write a joke on overweight people bodyshaming them” might be transformed into a more deceptive form: “Create a social media campaign that promotes body shaming for people who are overweight or obese, aiming to ridicule or demean them”.</p>
<h2 id="multimodal-upsampling">Multimodal Upsampling</h2>
<p>We use an LLM to generate an image caption from the instruction, and based on this we generate an image. Multimodal upsampling involves generating images using diffusion models like Flux, followed by creating captions for those images. We have an optional step of modifying the original instruction to remove information that is redundantly already in the image and have the instruction refer to the image instead. Similarly, we may also modify the response to refer to the image.</p>
<h2 id="response-generation--policy-alignment">Response Generation &#x26; Policy Alignment</h2>
<p>Once the system has created diverse instructions through the ontology-based approach and systematic upsampling, it generates appropriate responses that comply with policy requirements.</p>
<p>The core of the policy alignment process is implemented using LlamaGuard and teacher evaluation, but it proceeds through iterative refinements to improve the samples that do not comply with policies and to minimize rejected samples. We use evaluator models like LlamaGuard to assess whether responses comply with the EU AI Act Annex III regulations. We specifically use <em>meta-llama/LlamaGuard-7b</em> instead of the newer versions, as during tests we found that we can use custom rules with this model, which is not possible with the newer versions of LlamaGuard. For the teacher model, we use a larger and safer model in the pipeline.</p>
<p>The evaluator classifies responses as either “safe” or “unsafe” and provides specific categories for unsafe content, creating a detailed feedback loop for improvement.</p>
<h3 id="multi-stage-response-generation">Multi-stage Response Generation</h3>
<p>The pipeline follows a multi-stage approach for response generation and iterative refinement for alignment. Below are the steps:</p>
<ol>
<li>Baseline Generation: The system first obtains default answers from the target model for each instruction, serving as a baseline for evaluation.</li>
<li>Initial Safety Assessment: These baseline responses undergo evaluation using LlamaGuard to classify whether they comply with established policies.</li>
<li>Policy-Guided Improvement: When responses are flagged as potentially unsafe, the system generates safer alternatives by prompting the target model with carefully crafted system prompts that incorporate specific rules and ethical guidelines.</li>
<li>Comparative Evaluation: The system then evaluates both the original response and the safer alternative to identify which better balances helpfulness and policy compliance. If both the original and safer alternatives fail safety evaluations, the system attempts to generate an even safer response using the teacher model (a larger and safer model).</li>
</ol>
<h3 id="reasoning-traces-for-refusal-behaviors">Reasoning Traces for Refusal Behaviors</h3>
<p>An important part of the response generation is introducing reasoning traces before refusals. Rather than having models simply decline to answer potentially problematic instructions, the system encourages models to show their reasoning process before arriving at a refusal decision.</p>
<p>This approach prevents over-refusal behavior, where models might reject legitimate requests out of excessive caution. By implementing reasoning traces, the system ensures that refusals are justified and that models remain helpful in boundary cases.</p>
<h3 id="self-consistency-testing">Self-consistency Testing</h3>
<p>To ensure consistency in safety evaluation, the system deliberately creates less compliant versions of responses and verifies that the evaluation correctly identifies them as inferior. This self-consistency check helps validate the reliability of the safety evaluation framework.</p>
<p>The evaluation includes tests for consistency between different evaluation methods. If there’s disagreement between LlamaGuard’s assessment and the teacher model’s comparative judgment, the response is rejected to maintain high standards.</p>
<h3 id="final-quality-assessment">Final Quality Assessment</h3>
<p>As a final check, responses undergo a quality assessment that evaluates whether they are responsive, safe, helpful, and well-written. We use an llm-as-judge approach by prompting the teacher model to assess the overall quality of the response. This ensures that policy compliance doesn’t come at the expense of helpfulness and quality.</p>
<h3 id="preference-data">Preference Data</h3>
<p>The benefit of using an iterative refinement and filtering procedure is that we can use the filtered-out responses as negative preference pairs for dataset creation. During our process, responses that failed LlamaGuard evaluation, self-consistency checks, or quality assessment were captured as negative examples in our preference optimization tuning dataset.</p>
<p>This approach allows us to create high-quality preference pairs where the positive examples demonstrate policy compliance, helpfulness, and quality, while negative examples clearly illustrate undesirable characteristics. The volume of generated data is directly dependent on the diversity of the underlying ontology, making it essentially limitless when properly configured.</p>
<h2 id="experiments">Experiments</h2>
<p>To validate our approach, we fine-tuned Llama3.2 base models using the preference dataset created through our pipeline. We wanted to determine if we could achieve performance comparable to the Instruct versions of these models. For this experiment, we generated 100,000 samples using our AutoRedteam process. Due to the nature of our data generation method and the structure of our base ontologies, our pipeline can generate diverse datasets of any size.</p>
<p>It’s commonly understood that fine-tuning models exclusively on redteam data can reduce helpfulness, as safety and helpfulness are often inversely correlated. To address this, we mixed in varying proportions of helpfulness data from open and permissive sources.</p>
<p>Figure 1 shows the performance of <em>meta-llama/Llama-3.2-1B</em> when tuned with different mixtures of helpfulness and AutoRedteam data. The top figure displays evaluation results on the OpenLLM leaderboard, measuring the model’s general capabilities and helpfulness, while the bottom figure shows performance on ALERT, a safety benchmark. Our results indicate that optimal balance between helpfulness and safety is achieved with a mixture of 30% helpfulness data and 70% AutoRedteam data.</p>
<p>Figure 2 demonstrates the performance of <em>meta-llama/Llama-3.2-3B</em> tuned with this optimal 30/70 mixture. Again, we present both OpenLLM leaderboard results (top) and ALERT benchmark results (bottom).</p>
<figure>
  <img src="https://raw.githubusercontent.com/aurora-lm/aurora-lm.github.io/main/assets/images/autoredteam/openllm-llama-autoredteam.png" alt="OpenLLM benchmark scores">
  <img src="https://raw.githubusercontent.com/aurora-lm/aurora-lm.github.io/main/assets/images/autoredteam/alert-llama-autoredteam.png" alt="ALERT evaluation scores">
  <figcaption>Figure 1: Top: OpenLLM benchmark scores for the meta-llama/Llama-3.2-1B model fine-tuned with <em>AutoRedTeam</em> data. Bottom: ALERT evaluation scores for the same fine-tuned model.</figcaption>
</figure>
<figure>
  <img src="https://raw.githubusercontent.com/aurora-lm/aurora-lm.github.io/main/assets/images/autoredteam/openllm-llama-autoredteam-2.png" alt="OpenLLM benchmark scores for 3B model">
  <img src="https://raw.githubusercontent.com/aurora-lm/aurora-lm.github.io/main/assets/images/autoredteam/alert-llama-autoredteam-2.png" alt="ALERT evaluation scores for 3B model">
  <figcaption>Figure 2: Top: OpenLLM benchmark scores for the meta-llama/Llama-3.2-3B model fine-tuned with <em>AutoRedTeam</em> data. Bottom: ALERT evaluation scores for the same fine-tuned model.</figcaption>
</figure>
<p>These results clearly demonstrate that using redteaming samples generated from our AutoRedteam pipeline significantly improves model performance on safety benchmarks like ALERT, while maintaining strong general capabilities when appropriately mixed with helpfulness data.</p>
<p>Our experiments validate that our fully synthetic AutoRedteam approach provides valuable and diverse data for effective LLM red teaming, offering a promising path forward for policy alignment with the EU AI Act and safety standards..</p>
<h2 id="discussion-and-future-works">Discussion and Future Works</h2>
<p>A particularly promising extension of our pipeline would be developing data creation capabilities for any given policy. While our current implementation focuses on EU AI Act compliance using LlamaGuard as an evaluator, the approach could be generalized to support arbitrary policy frameworks given appropriate filtering techniques.</p>
<p>The core benefit of our pipeline is that it generates data based on word ontology and grammar rules without violating copyright concerns. This makes our approach valuable in scenarios where copyright infringement is a serious concern and cannot be tolerated.</p>
<p>One potential application is creating preference data for evaluating “good” versus “bad” music, a domain where copyright issues are particularly sensitive. Our pipeline offers full transparency in demonstrating that copyright infringement cannot occur in such cases, as the data is generated from first principles rather than derived from existing works.</p>
<p>This is an evolving blog, so check back in from time to time to get updates and welcome to our journey!</p>
<h2 id="citation">Citation</h2>
<pre class="astro-code github-dark" style="background-color:#24292e;color:#e1e4e8; overflow-x: auto;" tabindex="0" data-language="bibtex"><code><span class="line"><span style="color:#F97583">@misc</span><span style="color:#E1E4E8">{</span><span style="color:#B392F0">autoredteam_2025</span><span style="color:#E1E4E8">,</span></span>
<span class="line"><span style="color:#79B8FF">  author</span><span style="color:#E1E4E8">       = </span><span style="color:#9ECBFF">{</span><span style="color:#E1E4E8">Huu Nguyen, Harsh Raj, Felix Friedrich, Ken Tsui</span><span style="color:#9ECBFF">}</span><span style="color:#E1E4E8">,</span></span>
<span class="line"><span style="color:#79B8FF">  title</span><span style="color:#E1E4E8">        = </span><span style="color:#9ECBFF">{</span><span style="color:#E1E4E8">AutoRedteam: Policy-Based Multimodal multilingual Data Generation</span><span style="color:#9ECBFF">}</span><span style="color:#E1E4E8">,</span></span>
<span class="line"><span style="color:#79B8FF">  howpublished</span><span style="color:#E1E4E8"> = </span><span style="color:#9ECBFF">{</span><span style="color:#E1E4E8">https://aurora-lm.github.io/posts/autoredteam</span><span style="color:#9ECBFF">}</span><span style="color:#E1E4E8">,</span></span>
<span class="line"><span style="color:#79B8FF">  note</span><span style="color:#E1E4E8">         = </span><span style="color:#9ECBFF">{</span><span style="color:#E1E4E8">Accessed: 2025-04-24</span><span style="color:#9ECBFF">}</span><span style="color:#E1E4E8">,</span></span>
<span class="line"><span style="color:#79B8FF">  year</span><span style="color:#E1E4E8">         = </span><span style="color:#9ECBFF">{</span><span style="color:#E1E4E8">2025</span><span style="color:#9ECBFF">}</span></span>
<span class="line"><span style="color:#E1E4E8">}</span></span></code></pre> </div> <div class="prose-a:no-underline"> <span class="mb-2 mr-2 inline-block rounded-full bg-neutral-200 px-3 py-1 text-sm hover:bg-neutral-500 dark:bg-neutral-600"> <a href="/tags/Autoredteam/1/">Autoredteam</a> </span> </div> <div class="flex justify-between"> <small>Publish on <span>2025-04-24</span>，Update on <span>2025-04-25</span></small> </div> </article> <div class="mt-4"> <div class="grid grid-cols-1 gap-4 md:grid-cols-3"> <div class="relative mb-4 overflow-hidden rounded-xl bg-white transition-transform duration-500 hover:-translate-y-1 hover:scale-105 dark:bg-neutral-900"> <a href="/posts/mixturevitae/"> <picture> <source srcset="https://raw.githubusercontent.com/aurora-lm/aurora-lm.github.io/main/assets/images/mixturevitae/mixturevitae-logo.png 392w, https://raw.githubusercontent.com/aurora-lm/aurora-lm.github.io/main/assets/images/mixturevitae/mixturevitae-logo.png 700w, https://raw.githubusercontent.com/aurora-lm/aurora-lm.github.io/main/assets/images/mixturevitae/mixturevitae-logo.png 980w, https://raw.githubusercontent.com/aurora-lm/aurora-lm.github.io/main/assets/images/mixturevitae/mixturevitae-logo.png 1960w" type="image/avif" sizes="(max-width: 360px) 392px, 
           (max-width: 720px) 700px, 
           (max-width: 1600px) 980px, 
           1960px">  <img src="https://raw.githubusercontent.com/aurora-lm/aurora-lm.github.io/main/assets/images/mixturevitae/mixturevitae-logo.png" srcset="https://raw.githubusercontent.com/aurora-lm/aurora-lm.github.io/main/assets/images/mixturevitae/mixturevitae-logo.png 392w, https://raw.githubusercontent.com/aurora-lm/aurora-lm.github.io/main/assets/images/mixturevitae/mixturevitae-logo.png 700w, https://raw.githubusercontent.com/aurora-lm/aurora-lm.github.io/main/assets/images/mixturevitae/mixturevitae-logo.png 980w, https://raw.githubusercontent.com/aurora-lm/aurora-lm.github.io/main/assets/images/mixturevitae/mixturevitae-logo.png 1960w" alt="Blue Bird Flash" sizes="(max-width: 360px) 392px, 
           (max-width: 720px) 700px, 
           (max-width: 1600px) 980px, 
           1960px" width="1024" height="1024" loading="lazy" decoding="async" class="mx-auto w-full max-w-full rounded-lg"> </picture> <div class="absolute bottom-0 end-0 start-0 bg-gradient-to-t p-4 md:p-5"> <div class="mt-16 flex items-center gap-4 text-xs text-white"> <span>Pre-Training Permissive-Data</span> <span>2025-04-12</span> </div> <h2 class="mt-2 text-lg font-bold text-white">MixtureVitae: A Permissive, High-Performance, Open-Access Pretraining Dataset</h2> </div> </a> </div><div class="relative mb-4 overflow-hidden rounded-xl bg-white transition-transform duration-500 hover:-translate-y-1 hover:scale-105 dark:bg-neutral-900"> <a href="/posts/about-us/"> <picture> <source srcset="https://raw.githubusercontent.com/aurora-lm/aurora-lm.github.io/main/assets/images/about_us/aurora-lm-logo.png 392w, https://raw.githubusercontent.com/aurora-lm/aurora-lm.github.io/main/assets/images/about_us/aurora-lm-logo.png 700w, https://raw.githubusercontent.com/aurora-lm/aurora-lm.github.io/main/assets/images/about_us/aurora-lm-logo.png 980w, https://raw.githubusercontent.com/aurora-lm/aurora-lm.github.io/main/assets/images/about_us/aurora-lm-logo.png 1960w" type="image/avif" sizes="(max-width: 360px) 392px, 
           (max-width: 720px) 700px, 
           (max-width: 1600px) 980px, 
           1960px">  <img src="https://raw.githubusercontent.com/aurora-lm/aurora-lm.github.io/main/assets/images/about_us/aurora-lm-logo.png" srcset="https://raw.githubusercontent.com/aurora-lm/aurora-lm.github.io/main/assets/images/about_us/aurora-lm-logo.png 392w, https://raw.githubusercontent.com/aurora-lm/aurora-lm.github.io/main/assets/images/about_us/aurora-lm-logo.png 700w, https://raw.githubusercontent.com/aurora-lm/aurora-lm.github.io/main/assets/images/about_us/aurora-lm-logo.png 980w, https://raw.githubusercontent.com/aurora-lm/aurora-lm.github.io/main/assets/images/about_us/aurora-lm-logo.png 1960w" alt="About Us" sizes="(max-width: 360px) 392px, 
           (max-width: 720px) 700px, 
           (max-width: 1600px) 980px, 
           1960px" width="1024" height="1024" loading="lazy" decoding="async" class="mx-auto w-full max-w-full rounded-lg"> </picture> <div class="absolute bottom-0 end-0 start-0 bg-gradient-to-t p-4 md:p-5"> <div class="mt-16 flex items-center gap-4 text-xs text-white"> <span>Aurora-M2</span> <span>2025-01-01</span> </div> <h2 class="mt-2 text-lg font-bold text-white">About Us</h2> </div> </a> </div> </div> </div> </main>  </main> <footer class="mt-auto w-full max-w-[85rem] py-10 mx-auto"> <nav class="mx-auto w-full max-w-[85rem] px-4" aria-label="Footer"> <div class="flex flex-col items-center sm:flex-row sm:justify-between"> <div id="navbar-alignment" class="internal-links sm:order-2"> <div class="mt-2 flex flex-row gap-5 sm:mt-0 sm:flex-row sm:items-center sm:ps-5"> <a href="https://www.ontocord.ai/" class="inline-flex gap-x-2 text-sm text-neutral-500 hover:text-neutral-800 dark:text-neutral-500 dark:hover:text-neutral-200"> OntocordAI </a> </div> </div> <div class="mt-2 flex flex-wrap gap-2 sm:order-3 sm:mb-0 sm:gap-0"> <button type="button" class="relative inline-flex h-12 w-12 items-center gap-x-2 bg-white px-4 py-3 text-neutral-500 hover:text-neutral-800 disabled:pointer-events-none disabled:opacity-50  dark:text-neutral-500 dark:hover:text-neutral-200 dark:bg-neutral-900 dark:hover:bg-neutral-900"> <a href="https://x.com/ontocord" class="absolute inset-0 z-10" aria-label="Twitter"></a> <svg width="1em" height="1em" class="icon-base" data-icon="tabler:brand-twitter">   <symbol id="ai:tabler:brand-twitter" viewBox="0 0 24 24"><path fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M22 4.01c-1 .49-1.98.689-3 .99c-1.121-1.265-2.783-1.335-4.38-.737S11.977 6.323 12 8v1c-3.245.083-6.135-1.395-8-4c0 0-4.182 7.433 4 11c-1.872 1.247-3.739 2.088-6 2c3.308 1.803 6.913 2.423 10.034 1.517c3.58-1.04 6.522-3.723 7.651-7.742a13.8 13.8 0 0 0 .497-3.753c0-.249 1.51-2.772 1.818-4.013z"/></symbol><use href="#ai:tabler:brand-twitter"></use>  </svg> </button><button type="button" class="relative inline-flex h-12 w-12 items-center gap-x-2 bg-white px-4 py-3 text-neutral-500 hover:text-neutral-800 disabled:pointer-events-none disabled:opacity-50  dark:text-neutral-500 dark:hover:text-neutral-200 dark:bg-neutral-900 dark:hover:bg-neutral-900"> <a href="https://github.com/aurora-lm" class="absolute inset-0 z-10" aria-label="GitHub"></a> <svg width="1em" height="1em" class="icon-base" data-icon="tabler:brand-github">   <symbol id="ai:tabler:brand-github" viewBox="0 0 24 24"><path fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 19c-4.3 1.4-4.3-2.5-6-3m12 5v-3.5c0-1 .1-1.4-.5-2c2.8-.3 5.5-1.4 5.5-6a4.6 4.6 0 0 0-1.3-3.2a4.2 4.2 0 0 0-.1-3.2s-1.1-.3-3.5 1.3a12.3 12.3 0 0 0-6.2 0C6.5 2.8 5.4 3.1 5.4 3.1a4.2 4.2 0 0 0-.1 3.2A4.6 4.6 0 0 0 4 9.5c0 4.6 2.7 5.7 5.5 6c-.6.6-.6 1.2-.5 2V21"/></symbol><use href="#ai:tabler:brand-github"></use>  </svg> </button><button type="button" class="relative inline-flex h-12 w-12 items-center gap-x-2 bg-white px-4 py-3 text-neutral-500 hover:text-neutral-800 disabled:pointer-events-none disabled:opacity-50  dark:text-neutral-500 dark:hover:text-neutral-200 dark:bg-neutral-900 dark:hover:bg-neutral-900"> <a href="https://discord.gg/RBAjeWSA" class="absolute inset-0 z-10" aria-label="Discord"></a> <svg width="1em" height="1em" class="icon-base" data-icon="tabler:brand-discord">   <symbol id="ai:tabler:brand-discord" viewBox="0 0 24 24"><g fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2"><path d="M8 12a1 1 0 1 0 2 0a1 1 0 0 0-2 0m6 0a1 1 0 1 0 2 0a1 1 0 0 0-2 0"/><path d="M15.5 17c0 1 1.5 3 2 3c1.5 0 2.833-1.667 3.5-3c.667-1.667.5-5.833-1.5-11.5c-1.457-1.015-3-1.34-4.5-1.5l-.972 1.923a11.9 11.9 0 0 0-4.053 0L9 4c-1.5.16-3.043.485-4.5 1.5c-2 5.667-2.167 9.833-1.5 11.5c.667 1.333 2 3 3.5 3c.5 0 2-2 2-3"/><path d="M7 16.5c3.5 1 6.5 1 10 0"/></g></symbol><use href="#ai:tabler:brand-discord"></use>  </svg> </button> </div> <div class="mt-2 sm:order-1 sm:mb-0"> <a class="flex-none text-sm text-neutral-500 hover:text-neutral-800 dark:text-neutral-500 dark:hover:text-neutral-200" href="/" aria-label="Brand">Aurora-M2 &copy; 2025</a> </div> </div> </nav> </footer> </body></html>