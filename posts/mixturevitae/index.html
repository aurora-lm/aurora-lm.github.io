<!DOCTYPE html><html lang="en"> <head><!-- Global Metadata --><meta charset="utf-8"><meta name="viewport" content="width=device-width,initial-scale=1"><link rel="icon" type="image/svg+xml" href="https://raw.githubusercontent.com/aurora-lm/aurora-lm.github.io/main/assets/images/about_us/aurora-lm-logo.png"><meta name="generator" content="Astro v5.1.1"><!-- Canonical URL --><link rel="canonical" href="https://aurora-lm.github.io/posts/mixturevitae/"><!-- Sitemap --><link rel="sitemap" href="/sitemap-index.xml"><!-- Primary Meta Tags --><title>MixtureVitae: A Permissive, High-Performance, Open-Access Pretraining Dataset</title><meta name="title" content="MixtureVitae: A Permissive, High-Performance, Open-Access Pretraining Dataset"><meta name="description" content="We introduce an open source pretraining dataset designed to lower legal copyright uncertainty while still delivering high-performance. Our dataset, called MixtureVitae, is intended to train high-quality LLMs and create transparency and open access for AI research."><!-- Open Graph / Facebook --><meta property="og:type" content="website"><meta property="og:url" content="https://aurora-lm.github.io/posts/mixturevitae/"><meta property="og:title" content="MixtureVitae: A Permissive, High-Performance, Open-Access Pretraining Dataset"><meta property="og:description" content="We introduce an open source pretraining dataset designed to lower legal copyright uncertainty while still delivering high-performance. Our dataset, called MixtureVitae, is intended to train high-quality LLMs and create transparency and open access for AI research."><meta property="og:image" content="https://aurora-lm.github.io/blog-placeholder-1.avif"><!-- Twitter --><meta property="twitter:card" content="summary_large_image"><meta property="twitter:url" content="https://aurora-lm.github.io/posts/mixturevitae/"><meta property="twitter:title" content="MixtureVitae: A Permissive, High-Performance, Open-Access Pretraining Dataset"><meta property="twitter:description" content="We introduce an open source pretraining dataset designed to lower legal copyright uncertainty while still delivering high-performance. Our dataset, called MixtureVitae, is intended to train high-quality LLMs and create transparency and open access for AI research."><meta property="twitter:image" content="https://aurora-lm.github.io/blog-placeholder-1.avif"><!-- Preline CSS --><script type="module" src="/_astro/BaseHead.astro_astro_type_script_index_0_lang.BtT675nX.js"></script><link rel="stylesheet" href="/_astro/_page_.a1X1-JMm.css">
<style>[data-astro-image]{width:100%;height:auto;-o-object-fit:var(--fit);object-fit:var(--fit);-o-object-position:var(--pos);object-position:var(--pos);aspect-ratio:var(--w) / var(--h)}[data-astro-image=responsive]{max-width:calc(var(--w) * 1px);max-height:calc(var(--h) * 1px)}[data-astro-image=fixed]{width:calc(var(--w) * 1px);height:calc(var(--h) * 1px)}
</style><script type="module" src="/_astro/page.DTIbhfSr.js"></script>
<script>!(function(w,p,f,c){if(!window.crossOriginIsolated && !navigator.serviceWorker) return;c=w[p]=Object.assign(w[p]||{},{"lib":"/~partytown/","debug":false});c[f]=(c[f]||[]).concat(["dataLayer.push"])})(window,'partytown','forward');/* Partytown 0.10.2 - MIT builder.io */
const t={preserveBehavior:!1},e=e=>{if("string"==typeof e)return[e,t];const[n,r=t]=e;return[n,{...t,...r}]},n=Object.freeze((t=>{const e=new Set;let n=[];do{Object.getOwnPropertyNames(n).forEach((t=>{"function"==typeof n[t]&&e.add(t)}))}while((n=Object.getPrototypeOf(n))!==Object.prototype);return Array.from(e)})());!function(t,r,o,i,a,s,c,d,l,p,u=t,f){function h(){f||(f=1,"/"==(c=(s.lib||"/~partytown/")+(s.debug?"debug/":""))[0]&&(l=r.querySelectorAll('script[type="text/partytown"]'),i!=t?i.dispatchEvent(new CustomEvent("pt1",{detail:t})):(d=setTimeout(v,1e4),r.addEventListener("pt0",w),a?y(1):o.serviceWorker?o.serviceWorker.register(c+(s.swPath||"partytown-sw.js"),{scope:c}).then((function(t){t.active?y():t.installing&&t.installing.addEventListener("statechange",(function(t){"activated"==t.target.state&&y()}))}),console.error):v())))}function y(e){p=r.createElement(e?"script":"iframe"),t._pttab=Date.now(),e||(p.style.display="block",p.style.width="0",p.style.height="0",p.style.border="0",p.style.visibility="hidden",p.setAttribute("aria-hidden",!0)),p.src=c+"partytown-"+(e?"atomics.js?v=0.10.2":"sandbox-sw.html?"+t._pttab),r.querySelector(s.sandboxParent||"body").appendChild(p)}function v(n,o){for(w(),i==t&&(s.forward||[]).map((function(n){const[r]=e(n);delete t[r.split(".")[0]]})),n=0;n<l.length;n++)(o=r.createElement("script")).innerHTML=l[n].innerHTML,o.nonce=s.nonce,r.head.appendChild(o);p&&p.parentNode.removeChild(p)}function w(){clearTimeout(d)}s=t.partytown||{},i==t&&(s.forward||[]).map((function(r){const[o,{preserveBehavior:i}]=e(r);u=t,o.split(".").map((function(e,r,o){var a;u=u[o[r]]=r+1<o.length?u[o[r]]||(a=o[r+1],n.includes(a)?[]:{}):(()=>{let e=null;if(i){const{methodOrProperty:n,thisObject:r}=((t,e)=>{let n=t;for(let t=0;t<e.length-1;t+=1)n=n[e[t]];return{thisObject:n,methodOrProperty:e.length>0?n[e[e.length-1]]:void 0}})(t,o);"function"==typeof n&&(e=(...t)=>n.apply(r,...t))}return function(){let n;return e&&(n=e(arguments)),(t._ptf=t._ptf||[]).push(o,arguments),n}})()}))})),"complete"==r.readyState?h():(t.addEventListener("DOMContentLoaded",h),t.addEventListener("load",h))}(window,document,navigator,top,window.crossOriginIsolated);;(e=>{e.addEventListener("astro:before-swap",e=>{let r=document.body.querySelector("iframe[src*='/~partytown/']");if(r)e.newDocument.body.append(r)})})(document);</script></head> <body class="flex flex-col min-h-screen mx-auto max-w-6xl px-4 dark:prose-invert sm:px-6 lg:px-8 dark:bg-neutral-900"> <header class="flex flex-wrap md:justify-start md:flex-nowrap z-50 w-full py-7"> <nav class="relative max-w-7xl w-full flex flex-wrap md:grid md:grid-cols-12 basis-full items-center px-4 mx-auto" aria-label="Global"> <div class="md:col-span-3"> <a class="flex-none text-xl font-semibold text-neutral-900 hover:text-neutral-600 dark:text-neutral-400 dark:hover:text-neutral-200" href="/" aria-label="Astroverse"> Aurora-M2 </a> </div> <div class="flex items-center gap-x-2 ms-auto py-1 md:ps-6 md:order-3 md:col-span-3"> <button type="button" class="py-2 px-3 inline-flex items-center gap-x-2 text-sm font-medium rounded-xl border border-transparent text-black hover:bg-neutral-100 dark:text-white dark:hover:bg-neutral-700 transition disabled:opacity-50 disabled:pointer-events-none" onclick="window.location.href='/search/'"> <svg width="1em" height="1em" class="icon-base" data-icon="tabler:search">   <symbol id="ai:tabler:search" viewBox="0 0 24 24"><path fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M3 10a7 7 0 1 0 14 0a7 7 0 1 0-14 0m18 11l-6-6"/></symbol><use href="#ai:tabler:search"></use>  </svg> </button> <button type="button" class="hs-dark-mode hs-dark-mode-active:hidden inline-flex items-center gap-x-2 py-2 px-3 rounded-full text-sm text-black hover:bg-white/20" data-hs-theme-click-value="dark"> <svg width="1em" height="1em" class="icon-base" data-icon="tabler:sun-filled">   <symbol id="ai:tabler:sun-filled" viewBox="0 0 24 24"><path fill="currentColor" d="M12 19a1 1 0 0 1 .993.883L13 20v1a1 1 0 0 1-1.993.117L11 21v-1a1 1 0 0 1 1-1m6.313-2.09l.094.083l.7.7a1 1 0 0 1-1.32 1.497l-.094-.083l-.7-.7a1 1 0 0 1 1.218-1.567zm-11.306.083a1 1 0 0 1 .083 1.32l-.083.094l-.7.7a1 1 0 0 1-1.497-1.32l.083-.094l.7-.7a1 1 0 0 1 1.414 0M4 11a1 1 0 0 1 .117 1.993L4 13H3a1 1 0 0 1-.117-1.993L3 11zm17 0a1 1 0 0 1 .117 1.993L21 13h-1a1 1 0 0 1-.117-1.993L20 11zM6.213 4.81l.094.083l.7.7a1 1 0 0 1-1.32 1.497l-.094-.083l-.7-.7A1 1 0 0 1 6.11 4.74zm12.894.083a1 1 0 0 1 .083 1.32l-.083.094l-.7.7a1 1 0 0 1-1.497-1.32l.083-.094l.7-.7a1 1 0 0 1 1.414 0M12 2a1 1 0 0 1 .993.883L13 3v1a1 1 0 0 1-1.993.117L11 4V3a1 1 0 0 1 1-1m0 5a5 5 0 1 1-4.995 5.217L7 12l.005-.217A5 5 0 0 1 12 7"/></symbol><use href="#ai:tabler:sun-filled"></use>  </svg> </button> <button type="button" class="hs-dark-mode hs-dark-mode-active:inline-flex hidden items-center gap-x-2 py-2 px-3 rounded-full text-sm text-white hover:bg-white/20" data-hs-theme-click-value="light"> <svg width="1em" height="1em" class="icon-base" data-icon="tabler:moon-filled">   <symbol id="ai:tabler:moon-filled" viewBox="0 0 24 24"><path fill="currentColor" d="M12 1.992a10 10 0 1 0 9.236 13.838c.341-.82-.476-1.644-1.298-1.31a6.5 6.5 0 0 1-6.864-10.787l.077-.08c.551-.63.113-1.653-.758-1.653h-.266l-.068-.006z"/></symbol><use href="#ai:tabler:moon-filled"></use>  </svg> </button> <div class="md:hidden"> <button type="button" class="hs-collapse-toggle size-[38px] flex justify-center items-center text-sm font-semibold rounded-xl text-black hover:bg-neutral-100 disabled:opacity-50 disabled:pointer-events-none dark:text-white dark:hover:bg-neutral-700" data-hs-collapse="#navbar-collapse-with-animation" aria-controls="navbar-collapse-with-animation" aria-label="Toggle navigation"> <svg width="1em" height="1em" class="hs-collapse-open:hidden flex-shrink-0 size-4" data-icon="tabler:menu-2">   <symbol id="ai:tabler:menu-2" viewBox="0 0 24 24"><path fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M4 6h16M4 12h16M4 18h16"/></symbol><use href="#ai:tabler:menu-2"></use>  </svg> <svg width="1em" height="1em" class="hs-collapse-open:block hidden flex-shrink-0 size-4" data-icon="tabler:menu-order">   <symbol id="ai:tabler:menu-order" viewBox="0 0 24 24"><path fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M4 10h16M4 14h16M9 18l3 3l3-3M9 6l3-3l3 3"/></symbol><use href="#ai:tabler:menu-order"></use>  </svg> </button> </div> </div> <div id="navbar-collapse-with-animation" class="hs-collapse hidden overflow-hidden transition-all duration-300 basis-full grow md:block md:w-auto md:basis-auto md:order-2 md:col-span-6"> <div class="flex flex-col gap-y-4 gap-x-0 mt-5 md:flex-row md:justify-center md:items-center md:gap-y-0 md:gap-x-7 md:mt-0"> <a href="/posts/about-us/" class="px-4 py-3 font-medium text-neutral-900 hover:text-neutral-600 dark:text-neutral-400 dark:hover:text-neutral-200"> About Us </a><a href="/category/One/1/" class="px-4 py-3 font-medium text-neutral-900 hover:text-neutral-600 dark:text-neutral-400 dark:hover:text-neutral-200"> Blog Posts </a><a href="/tags/" class="px-4 py-3 font-medium text-neutral-900 hover:text-neutral-600 dark:text-neutral-400 dark:hover:text-neutral-200"> Sort by Tags </a> </div> </div> </nav> </header> <main class="flex-grow">  <main> <article class="prose mx-auto dark:prose-invert"> <div class="prose-h1 text-center"> <h1>MixtureVitae: A Permissive, High-Performance, Open-Access Pretraining Dataset</h1> </div> <div> <picture> <source srcset="https://raw.githubusercontent.com/aurora-lm/aurora-lm.github.io/main/assets/images/mixturevitae/mixturevitae-logo.png 392w, https://raw.githubusercontent.com/aurora-lm/aurora-lm.github.io/main/assets/images/mixturevitae/mixturevitae-logo.png 700w, https://raw.githubusercontent.com/aurora-lm/aurora-lm.github.io/main/assets/images/mixturevitae/mixturevitae-logo.png 980w, https://raw.githubusercontent.com/aurora-lm/aurora-lm.github.io/main/assets/images/mixturevitae/mixturevitae-logo.png 1960w" type="image/avif" sizes="(max-width: 360px) 392px, 
           (max-width: 720px) 700px, 
           (max-width: 1600px) 980px, 
           1960px">  <img src="https://raw.githubusercontent.com/aurora-lm/aurora-lm.github.io/main/assets/images/mixturevitae/mixturevitae-logo.png" srcset="https://raw.githubusercontent.com/aurora-lm/aurora-lm.github.io/main/assets/images/mixturevitae/mixturevitae-logo.png 392w, https://raw.githubusercontent.com/aurora-lm/aurora-lm.github.io/main/assets/images/mixturevitae/mixturevitae-logo.png 700w, https://raw.githubusercontent.com/aurora-lm/aurora-lm.github.io/main/assets/images/mixturevitae/mixturevitae-logo.png 980w, https://raw.githubusercontent.com/aurora-lm/aurora-lm.github.io/main/assets/images/mixturevitae/mixturevitae-logo.png 1960w" alt="Blue Bird Flash" sizes="(max-width: 360px) 392px, 
           (max-width: 720px) 700px, 
           (max-width: 1600px) 980px, 
           1960px" width="1024" height="1024" loading="lazy" decoding="async" class="mx-auto w-full max-w-full rounded-lg"> </picture> </div> <div> <p><strong>By: <a href="https://www.linkedin.com/in/huu-ai-machine-learning/">Huu Nguyen</a>, <a href="hraj172.github.io">Harsh Raj</a>, <a href="https://www.linkedin.com/in/ken-tsui-06889b29/?originalSubdomain=uk">Ken Tsui</a>, <a href="https://scholar.google.com/citations?user=wcbZoCgAAAAJ&#x26;hl=en">Minh Chien Vu</a>, <a href="https://digantamisra98.github.io/">Diganta Misra</a>, <a href="https://mrcabbage972.github.io/">Victor May</a>, <a href="https://scholar.google.ru/citations?user=2KPv4VYAAAAJ&#x26;hl=en">Marianna Nezhurina</a>, <a href="https://scholar.google.com/citations?user=EvrlaSAAAAAJ&#x26;hl=en">Christoph Schuhmann</a>, <a href="https://scholar.google.com/citations?user=qj7YcjcAAAAJ&#x26;hl=en">Robert Kaczmarczyk</a> — Apr 12, 2025</strong></p>
<div align="center">
<p><strong>Huggingface:</strong> <a href="https://huggingface.co/datasets/ontocord/MixtureVitae" style="color: #1f6feb;" target="_blank"><strong>MixtureVitae</strong></a></p>
</div>
<p>Our blog is a way to share our journey with the wider community and is a living and organic document. We plan to update it continuously, alongside other posts on our site, as we further develop our data and models. In creating this dataset, we build on the work of industry giants such as Common Crawl, FineWeb, TxT360, Open License Corpus, Nemotron-CC, MAGAcorpus, Mint-PDF, and many others mentioned in the following sections.</p>
<p>We curated permissive data through two primary avenues: first, by sourcing known public domain, out-of-copyright, or permissively licensed materials including text, video, and image data under licenses such as CC-BY-SA or open source software licenses; and second, by leveraging government websites that are more likely to fall under fair use, with our ethical and legal reasoning discussed in <u>Our Position For Using Governmental Works</u> section.</p>
<p>In total, we collected approximately 300 billion text tokens of copyright-permissive data from various open sources, enriched with high-quality synthetic data generated through our own pipelines. We refer to this curated dataset and methodology as MixtureVitae.</p>
<p>Looking forward, we will shortly translate to multiple languages to reach 1T tokens. The token count will then be increased again by tokenizing the multimodal image and sound data.</p>
<p>There is a common notion that permissive-only data does not yield stronger models. Recently, big tech companies have <a href="https://www.theguardian.com/technology/2024/jan/08/ai-tools-chatgpt-copyrighted-material-openai">suggested</a> that stronger models aren’t possible without copyrighted content. We challenge that assumption through careful curation, systematic ablations, and synthetic data generation.</p>
<h2 id="mixturevitae">MixtureVitae</h2>
<p>MixtureVitae is a <em>carefully curated collection</em> of diverse, high-quality sources, designed from the ground up to lessen risk of copyright issues, and improve reliability, and diversity across domains and modalities.</p>
<h3 id="how-to-use">How to use</h3>
<p>The main portion of the dataset can be found at <a href="https://huggingface.co/datasets/ontocord/MixtureVitae">HuggingFace</a>.  However, there are subsets from the TXT360 and post-training datasets which we do not include in order to reduce duplications. You can find the links to these datasets below.</p>
<h3 id="whats-inside-the-mixturevitae">What’s Inside the MixtureVitae?</h3>
<p>We filtered, collated, reorganized and included data from various open corpora, and we created our own original data using synthetic data generation techniques. The corpus spans a rich variety of open datasets, curated datasets, and synthetic generations.</p>
<figure>
  <img src="https://raw.githubusercontent.com/aurora-lm/aurora-lm.github.io/main/assets/images/mixturevitae/pie-chart.jpg" alt="Proportions of Open Web, Curated, and Synthetic Dataset in MixtureVitae">
  <figcaption>Figure 1: The proportions of Open Web, Curated, and Synthetic Dataset in <em>MixtureVitae</em>.</figcaption>
</figure>
<h4 id="web-based-open-datasets">Web Based Open Datasets</h4>
<p>We filter a subset of the following web crawled datasets as described below.</p>
<ul>
<li><a href="https://arxiv.org/abs/2412.02595">Nemotron-cc</a>: A high-quality English dataset comprising 6.3 trillion tokens (4.4 trillion globally deduplicated original tokens and 1.9 trillion synthetically generated tokens), transformed from Common Crawl data. Nemotron-CC achieves better trade-offs between accuracy and data quantity by a combination of classifier ensembling, synthetic data rephrasing, and reduced reliance on heuristic filters.</li>
<li><a href="https://huggingface.co/datasets/HuggingFaceTB/smollm-corpus/tree/main/cosmopedia-v2">Cosmopedia v2</a>: An extensive synthetic dataset containing over 30 million files and 25 billion tokens, generated by Mixtral-8x7B-Instruct-v0.1. Cosmopedia includes a diverse range of topics and formats, including textbooks, blog posts, stories, and WikiHow articles, aiming to replicate the breadth of knowledge found in web datasets like RefinedWeb and RedPajama.</li>
<li><a href="https://huggingface.co/datasets/HuggingFaceFW/fineweb-edu">FineWeb-Edu</a>: A refined subset of FineWeb, focused on educational and instructive content. This dataset cleans vast web text into usable, narrative-style educational resources.</li>
<li><a href="https://huggingface.co/datasets/mlfoundations/MINT-1T-PDF-CC-2023-40">Mint-1T</a>: an open-source Multimodal Interleaved dataset containing 1 trillion text tokens and 3.4 billion images. It introduces new data sources, including PDFs and ArXiv papers. From this dataset, we collected the subset of documents originating from “.gov” sources.</li>
<li><a href="https://huggingface.co/datasets/SEACrowd/culturay">Cultura-Y</a>: A multilingual gem with contributions from over 70 languages, ensuring diverse cultural and linguistic representation.</li>
<li><a href="https://huggingface.co/datasets/LLM360/TxT360">TxT360</a>: A comprehensive dataset that globally deduplicates 99 CommonCrawl snapshots and 14 curated non-web data sources, including FreeLaw and PG-19. It includes approximately 5.7 trillion tokens of high-quality text data. We use the portion of the TxT-360 common crawl that has duplicate signals of 11 or above, meaning that these documents may be more important, since their content has been repeated.</li>
</ul>
<h4 id="curated-datasets">Curated Datasets</h4>
<ul>
<li><a href="https://huggingface.co/datasets/kernelmachine/open-license-corpus">Open License Corpus (OLC)</a>: We were heavily inspired by the OLC corpus. This dataset supports domain-specific learning in areas such as law, science, and technology. All data is sourced from permissively licensed material (e.g., CC-BY). We include selected sources across eight domains, including legal texts such as case law (public domain) and the Pile of Law (CC BY-SA subset); arXiv abstracts and subsets of S2ORC (public domain and CC BY-SA); news sources such as public domain news and Wikinews (CC BY-SA); and encyclopedic entries from Wikipedia (CC BY-SA). We collected and further cleaned and reformatted a subset of this collection  and/or removed certain citations that are likely too difficult for models to memorize reliably.</li>
<li><a href="https://huggingface.co/datasets/HuggingFaceM4/WebSight">WebSight</a>: The Websights dataset comprises synthetically generated HTML/CSS code representing English websites, each accompanied by a corresponding screenshot. It serves as a valuable resource for tasks such as generating user interface code from visual inputs. We rephrased the WebSights dataset so that it is framed as instructions and responses.</li>
<li><a href="https://huggingface.co/datasets/deepmind/pg19">PG-19</a>: We incorporated data from PG-19, comprising  28,752 books from Project Gutenberg published before 1919. This dataset serves as a valuable resource for training models to capture long-range dependencies in text. We use TXT360’s version of PG-19, and we further created shards of the books that are roughly 4096 tokens.</li>
<li><a href="https://free.law/">Freelaw</a>: Sourced from The Pile, this dataset comprises legal documents which improves the models knowledge about the law.</li>
<li><a href="https://huggingface.co/datasets/bigcode/the-stack">StackV1</a>: We included several subsets of the stack v1 dataset, modifying them removing headers to remove duplicate text. We further created a subset by clustering certain portions based on minhash and concatenating similar documents into single examples. Specifically, we flattened the python-edu portion by combining files from the same repository into a single example. Specifically, we included the following programming languages: Antlr, AppleScript, Awk, Batchfile, Clojure, CMake, CoffeeScript, Common Lisp, C/C++, C#, Emacs Lisp, Fortran, Go, Java, JavaScript, Jupyter scripts and structured data, Makefile, Mathematica, Perl, Python, Rust, Scheme, Shell, SQL, Tcl, TypeScript, and Yacc. We also included multilingual code to enhance language diversity. In addition to code, we incorporated non-coding data formats such as Markdown, HTML, and JSON to provide structured documentation.</li>
<li><a href="https://europat.net/">Euro-Pat</a>: A parallel multilingual dataset comprising patent documents from the United States Patent and Trademark Office (USPTO) and the European Patent Organisation (EPO). It aligns patents from different countries within the same “family,” providing multilingual context. To further enrich this resource, we have generated synthetic images corresponding to the patent documents.</li>
<li><a href="https://data.uspto.gov/">USPTO Data</a>: Derived from TXT360 and The Pile and further cleaned for use in Aurora-m1, this dataset provides a comprehensive collection of U.S. patent documents.</li>
<li><a href="https://cocodataset.org/#home">COCO Captions</a>: We recaptioned the coco-2017 dataset, commonly used to develop models for multimodal understanding.</li>
<li><a href="https://huggingface.co/datasets/laion/OIG">OIG</a>: We included certain subsets of the OIG dataset, rephrased with a LLM. Specifically, we incorporated the Unified SQL, Unified SKG, Abstract-Infil and Canadian Parliament subset of the OIG dataset.</li>
<li><a href="https://www.statmt.org/europarl/">Europarl</a>: A parallel corpus sourced from TxT360 extracted from the proceedings of the European Parliament, covering 21 European languages.</li>
<li><strong>10-K Filings</strong>: A dataset comprises a collection of 10-K filings, which are comprehensive annual reports filed by publicly traded companies to the U.S. Securities and Exchange Commission (SEC). These documents provide detailed insights into a company’s financial performance, risk factors, and management discussions.</li>
<li><a href="https://huggingface.co/datasets/aurora-m/aurora-m-dataset-part-1/tree/main/en">Atticus</a>: A comprehensive, expert-annotated dataset designed for research in legal contract review. It includes over 13,000 annotations across 510 commercial legal contracts, focusing on 41 categories of clauses deemed crucial in corporate transactions such as mergers and acquisitions.</li>
<li><a href="https://marketplace.sshopencloud.eu/dataset/ctbZd7">Aozora Bunko</a>: A digital library that hosts a vast collection of Japanese literary works that are in the public domain. The project aims to make classic Japanese literature accessible to the public by digitizing and providing texts in various formats.</li>
<li><strong>Hackernews</strong>: Sourced from OLC and TxT360, this dataset includes discussions and articles from the Hacker News platform.</li>
<li><strong>StackExchange</strong>: A dataset comprising of publicly available data from the Stack Exchange network, including users’  questions, answers, comments, and associated metadata. We included RedPajamav1’s and TxT360’s Stack Exchange dataset, encompassing a wide range of topics from the Stack Exchange network.</li>
<li><a href="https://huggingface.co/datasets/open-web-math/open-web-math">Openwebmath</a>: An open dataset of high-quality mathematical web text, containing 14.7 billion tokens extracted from mathematical webpages, intended for training language models in mathematical reasoning.</li>
<li><a href="https://en.wikibooks.org/wiki/Help:Database_download">Wikibooks</a>: A Wikimedia project that offers a collection of open-content textbooks and manuals across various subjects, including computing, science, humanities, and more. The content is collaboratively written and freely available under Creative Commons licenses.​</li>
<li><strong>Pubmed Abstracts</strong>: A dataset comprising abstracts from biomedical literature, sourced from PubMed. It includes millions of abstracts detailing research across various biomedical fields. This dataset was obtained from the Pile and TxT360 datasets.</li>
<li><a href="https://catalog.data.gov/dataset/pubmed-central-pmc?utm_source=chatgpt.com">Pubmed Central</a>: A free digital archive of full-text biomedical and life sciences journal literature. The dataset includes articles made available under licenses that permit text mining and other forms of reuse. It was extracted from the TxT360 dataset.</li>
<li><a href="https://reporter.nih.gov/exporter">NIH ExPorter</a>: A dataset includes administrative data on NIH-funded research projects. It provides detailed information on awarded grants, including abstracts, funding amounts, and project durations.​ This data was processed from the Pile dataset.</li>
<li><a href="https://huggingface.co/datasets/heegyu/elsevier-oa-cc-by">Elsevier-oa</a>: This corpus comprises over 40,000 open-access articles from Elsevier journals, available under the CC-BY license. It spans a wide range of scientific disciplines, such as medicine, biology, chemistry, physics, and engineering.</li>
<li><a href="https://github.com/LAION-AI/audio-dataset">Clap Synthetic Captions</a>: The CLAP dataset provides synthetic captions for audio clips, generated using advanced audio-language models. Includes captions for a large number of audio clips, with each clip accompanied by multiple synthetic captions.</li>
<li><strong>arXiv Summaries</strong>: Sourced from OLC, this dataset includes summaries of research papers from arXiv, facilitating research in scientific literature summarization.</li>
<li><strong>Wikipedia</strong>: We included portions of Wikipedia from TxT360’s subset. To limit non-educational value documents, we filtered out articles about currently living persons, such as sports stars, or shorter articles, including those about sporting events, inspired by Phi-3 and 4’s work. Additionally, we included clustered Wikipedia articles based on minhash clustering for languages: English (en), Italian (it), Polish (pl), Swedish (sv), and Dutch (nl).</li>
<li><a href="https://huggingface.co/datasets/hltcoe/megawika">Megawika</a>: A large-scale, multilingual, and cross-lingual dataset containing 30 million Wikipedia passages with their cleaned web citations in 50 languages. We used the original Wikipedia documents, select translations, and .gov web pages in this corpus, cleaning the content, aligning multilingual pairs, and appending relevant .gov webpages cited by Wikipedia. This results in a structured and contextualized knowledge base.</li>
<li><a href="https://huggingface.co/datasets/ontocord/VALID">VALID</a>: Developed by Ontocord.AI in collaboration with Grass and LAION, VALID includes approximately 720,000 Creative Commons-licensed YouTube videos. It combines: Video frames, Audio, Multilingual transcripts. This enables training on rich multimodal interactions, where models learn the interplay between vision, language, and sound. We use only the text portion of this dataset for now.</li>
<li><a href="https://huggingface.co/datasets/PleIAs/YouTube-Commons">Youtube Commons</a>: A collection of over 2 million YouTube videos released under CC-BY, providing 45 billion words of multilingual conversational transcripts. This hopefully will teach models how humans actually talk—across contexts, languages, and cultures. We collapsed transcripts for the same video into a single example so that the multilingual translations are presented together. We also performed text cleanup to remove some grammar and spelling issues.</li>
</ul>
<p>Additionally, We include widely-used open source and permissive post-training datasets from Hugging Face, reformatting them into a pretraining corpus by flattening their structures. While these are mostly intended for post-training, we incorporate these datasets at various stages of training to determine if they improve eval metrics. The current set of datasets incorporated are:​</p>
<ul>
<li><a href="https://huggingface.co/datasets/nvidia/OpenMathInstruct-1">nvidia/OpenMathInstruct-1</a>: A math instruction tuning dataset with 1.8M problem-solution pairs generated using permissively licensed <em>Mixtral-8x7B</em> model. The problems are from <a href="https://huggingface.co/datasets/openai/gsm8k">GSM8K</a> and <a href="(https://github.com/hendrycks/math)">MATH</a> training subsets and the solutions are synthetically generated by allowing Mixtral model to use a mix of text reasoning and code blocks executed by Python interpreter.</li>
<li><a href="https://huggingface.co/datasets/argilla/ifeval-like-data">ifeval-like-data</a>: This dataset contains instruction-response pairs synthetically generated using <em>Qwen/Qwen2.5-72B-Instruct</em> following the style of <a href="https://huggingface.co/datasets/google/IFEval">google/IFEval</a> dataset and verified for correctness with EleutherAI <em>lm-evaluation-harness</em>.</li>
<li><a href="https://huggingface.co/datasets/bespokelabs/Bespoke-Stratos-17k">Bespoke-Stratos-17k</a>: A dataset comprising 17,000 entries designed for model refinement and evaluation. It includes 5,000 coding-related samples sourced from the APPs and TACO datasets, 10,000 math-focused examples drawn from the AIME, MATH, and Olympiad subsets of the NuminaMATH dataset, and 1,000 science and puzzle problems from the STILL-2 dataset. The dataset is distilled from <em>DeepSeek-R1</em>.</li>
<li><a href="https://huggingface.co/datasets/cognitivecomputations/SystemChat-2.0">SystemChat-2.0</a>: A dataset designed for training conversational agents, including system-initiated dialogues across diverse scenarios. It is used to instill strong instruction-following abilities and adherence to system prompts.</li>
<li><a href="https://huggingface.co/datasets/Seungyoun/ultrafeedback_phi3_responses">Ultrafeedback_phi3_responses</a>: A subset of the <a href="https://huggingface.co/datasets/openbmb/UltraFeedback">Ultrafeedback</a> dataset containing responses generated by the <em>Phi-3</em> model. Since the model we are training shares architectural similarities and data characteristics with Phi, this subset is chosen to align closely with our target model’s behavior.</li>
<li><a href="https://huggingface.co/datasets/nguyenkhanh87/CaseHOLD_Phi4_Reasoning">CaseHOLD_Phi4_Reasoning</a>: A collection of <em>Phi-4</em> model responses on the <a href="https://github.com/reglab/casehold">CaseHOLD</a> dataset, which focuses on legal case holdings. This dataset supports the development of models with advanced legal reasoning capabilities.</li>
<li><a href="https://huggingface.co/Magpie-Align">Magpie Collection</a>: A collection of a set of high-quality instruction datasets generated using the Magpie technique - a self-synthesis approach where aligned language models autonomously create diverse instruction-response pairs. It includes <em>Magpie-Gemma2-Pro-534K-v0.1</em>, containing 534K entries distilled from <em>Gemma-2-27B-Instruct</em> for general alignment and performance; <em>Magpie-Phi3-Pro-1M-v0.1</em>, with 1 million professional-grade samples distilled from <em>microsoft/Phi-3-medium-128k-instruct</em> for advanced instruction tuning; and <em>Magpie-Qwen2.5-Coder-Pro-300K-v0.1</em>, comprising 300K code-focused samples distilled from <em>Qwen2.5-Coder-32B-Instruct</em> for code generation tasks.</li>
<li><a href="https://huggingface.co/datasets/tttonyyy/DeepScaler-QwQ_32b/blob/main/distilled_s0_e20000_20250309005632_final.json">DeepScaler-QwQ_32b</a>: A specialized collection derived from the <a href="https://github.com/agentica-project/rllm">DeepScalerR</a> dataset, comprising 20,000 samples. Each sample includes a question and its corresponding answer generated by the <em>Qwen/QwQ-32B</em> model, which is designed for advanced reasoning tasks such as mathematics and coding.</li>
<li><a href="https://huggingface.co/datasets/PrimeIntellect/SYNTHETIC-1">SYNTHETIC-1</a>: A reasoning-focused dataset distilled from <em>DeepSeek-R1</em> and annotated with a diverse set of verifiers, including LLM-based judges and symbolic mathematics verifiers. It includes a wide range of challenging tasks, such as competition-level math problems from <a href="https://huggingface.co/datasets/AI-MO/NuminaMath-CoT">NuminaMath</a>, coding problems from platforms like LeetCode, and curated datasets including <a href="https://huggingface.co/datasets/codeparrot/apps">APPS</a>, <a href="https://huggingface.co/datasets/deepmind/code_contests">CodeContests</a>, <a href="https://huggingface.co/datasets/MatrixStudio/Codeforces-Python-Submissions">Codeforces</a>, and <a href="https://huggingface.co/datasets/BAAI/TACO">TACO</a>. It also includes problems derived from real-world GitHub commits via the <a href="https://huggingface.co/datasets/bigcode/commitpackft">CommitPack</a> dataset, as well as questions sourced from the <a href="https://huggingface.co/datasets/HuggingFaceH4/stack-exchange-preferences">StackExchange dataset</a>.</li>
<li><a href="https://huggingface.co/datasets/oumi-ai/MetaMathQA-R1">MetaMathQA-R1</a>: S text dataset designed to train LLMs with DeepSeek-R1 level reasoning. The prompts in this dataset are derived from the training sets of GSM8K and MATH, with responses generated directly by <em>DeepSeek-R1</em>.
<a href="https://huggingface.co/datasets/open-r1/OpenR1-Math-220k">OpenR1-Math-220k</a>: A large-scale dataset for mathematical reasoning. It consists of 220k math problems with two to four reasoning traces generated by <em>DeepSeek R1</em> for problems from <em>NuminaMath 1.5</em>. The traces were verified using <a href="https://github.com/huggingface/Math-Verify">Math Verify</a> for most samples and <em>Llama-3.3-70B-Instruct</em> as a judge for 12% of the samples.</li>
<li><a href="https://huggingface.co/datasets/CharlieDreemur/OpenManus-RL">OpenManus-RL</a>: Combines agent trajectories from <a href="https://huggingface.co/datasets/THUDM/AgentInstruct">AgentInstruct</a>, <a href="https://huggingface.co/datasets/internlm/Agent-FLAN">Agent-FLAN</a>, and <a href="https://huggingface.co/datasets/AgentGym/AgentTraj-L">AgentTraj-L</a> (AgentGym) with key features including the <a href="https://react-lm.github.io/">ReAct</a> prompting framework, structured training (separate format and reasoning learning), and anti-hallucination techniques (negative samples and environment grounding). Covers six domains: Operating Systems, Databases, Web, Knowledge Graphs, Household, and E-commerce.</li>
</ul>
<h4 id="synthetic-data">Synthetic Data</h4>
<ul>
<li><strong>Multiple-Choice Question (MCQ) Generation</strong>: We generate multiple-choice questions (MCQs) derived from rich knowledge sources such as GenericsKB, as well as abstract infill templates from the <a href="https://laion.ai/blog/oig-dataset/">OIG dataset</a>. These MCQs are intended to promote the ability to answer multiple choice questions.</li>
<li><strong>Synthetic Stories</strong>: We generated synthetic stories similar to <a href="https://huggingface.co/datasets/roneneldan/TinyStories">TinyStories</a>, based on datasets like <a href="https://huggingface.co/datasets/ontocord/atomic_2024">Atomic 2024</a>, and select portions of the <a href="https://huggingface.co/datasets/deepmind/pg19">PG-19</a> dataset.</li>
<li><strong>Mathematical Generation</strong>:​
<ul>
<li>We create math textbooks for specific complex topics by combining mathematical instruction seed data with open-source mathematical web texts. The goal of this dataset is to teach the model about basic math such as arithmetic and algebra.</li>
<li>We also create synthetic math questions and answers to teach basic math as well.</li>
</ul>
</li>
<li><strong>Instruction Generation</strong>: The instruction generation pipeline creates structured instructions, stories, and data analysis summaries, similar to Ultra-Magpie from <a href="https://arxiv.org/abs/2502.02737v1">SmolLM</a>, but without editing instructions.</li>
</ul>
<figure>
  <img src="https://raw.githubusercontent.com/aurora-lm/aurora-lm.github.io/main/assets/images/mixturevitae/flow.png" alt="The process of filtering and compiling MixtureVitae">
  <figcaption>Figure 2: Flowchart illustrating the process of filtering and compiling <em>MixtureVitae</em>.</figcaption>
</figure>
<h3 id="how-do-we-filter-web-based-data">How Do We Filter Web Based Data?</h3>
<h4 id="permissive-filtering">Permissive filtering</h4>
<p>We performed a “pseudo-crawl” of the “open web dataset” for .gov and similar websites. And we also searched for the keywords “CC-BY-SA” and similar keywords and heuristics. We also performed removal of documents with spam like keywords in English, and a high proportion of obscene or offensive words or child sexual abuse materials (CSAM) words in multiple languages.</p>
<h4 id="dedup-and-heuristic-filtering">Dedup and heuristic filtering</h4>
<p>Then we perform a global deduplication (across web based documents) of these sources using only a prefix based matching of the documents. This is because the source datasets have been already deduplicated, so we perform only light global deduplication. We then remove common ngrams that begins or ends documents as these are sometimes generic headers such as “Home | Search” etc. We find sentence duplicates and remove these if they have low proportions of stopwords, as we find these are likely uninformative text. We augment other sentence duplicates using a wordnet synonym substitution method. We also perform filtering of documents with high proportions of obscene words, adult content and content involving minors and sexual abuse.</p>
<h4 id="fasttext-filtering">Fasttext Filtering</h4>
<p>One of the challenges of .gov web data  is that it can skew heavily toward regulatory or compliance-heavy content, leading to overrepresentation of certain tones or subject matter. To avoid a narrow, one-note model, we implemented genre and domain balancing — a process that boosts the proportion of diverse and underrepresented content types.</p>
<p><strong>Classification.</strong> We implemented multi-layered FastText classifiers to give us more insight into our data and to enable us to sample diverse subsets.</p>
<ul>
<li><strong>Domain Classification</strong>: We used data from <a href="https://huggingface.co/datasets/HuggingFaceFW/fineweb">FineWeb</a> which categorizes text based on a standard set of taxonomies. This dataset was used to train a fastText classifier, which we then used to classify a large portion of our text. We use this model to classify a large portion of our text.</li>
<li><strong>Classification Based on Pile Type</strong>: We developed a fastText classifier to identify and categorize content from various sources present in the Pile dataset. The categories follows the sources in this dataset, including Pile-CC, PubMed Central, Books3, OpenWebText2, ArXiv, Github, FreeLaw, Stack Exchange, USPTO, Backgrounds, PubMed Abstracts, Gutenberg (PG-19), OpenSubtitles, Wikipedia (en), DM Mathematics, Ubuntu IRC, BookCorpus2, EuroParl, HackerNews, YoutubeSubtitles, PhilPapers, NIH ExPorter, and Enron Emails.  Note that we do not actually include most of these datasets from the Pile due to copyright concerns. Rather, we have classified our permissive text to help us decide on how to maintain diversity across domains. This classifier produces a lower quality signal, but we include this for researcher’s usage.</li>
<li><strong>Register (Genres)</strong>: We employ <a href="https://turkunlp.org/register-annotation-docs/">TurkuNLP’s FastText classifier</a> to give us insight into the different registers (genres) in our dataset, ultimately allowing us to appropriately balancing types of contents. The classifier covers a wide array of web text styles, including Narrative, Informational Description, Opinion, Interactive Discussion, How-to/Instruction, Informational Persuasion, Lyrical, and Spoken. This classification draws from the TurkuNLP annotation framework, which identifies text purpose (e.g., to narrate, instruct, describe, persuade, or express opinion), to identify diverse genres sources like blogs, news reports, Q&#x26;A forums, and instructional content.</li>
<li><strong>Limitations.</strong> At present, our classifiers are mainly English based and do not classify well non-English text.</li>
</ul>
<p><strong>Ranking.</strong> We also implemented multi-layered FastText classifiers to rank documents for quality data.</p>
<ul>
<li><strong>Mathematics Ranker</strong>: To enhance mathematical reasoning, similar to DeepSeekMath, a fastText classifier is trained to recall mathematics text from the web. Our initial model uses 800,000 samples from <a href="https://arxiv.org/abs/2304.08442">MiniPile</a>, which represents a diverse subset of Pile as negative class, and 800,000 samples from <a href="https://huggingface.co/datasets/open-web-math/open-web-math">openwebmath</a> as positive class. However, as we observe the initial classifier is not sensitive to latex mathematical symbols, and also inspired from DataComp-LM, we include instruction-format data drawing from <a href="https://huggingface.co/datasets/math-ai/StackMathQA">StackMathQA</a>, <a href="https://huggingface.co/datasets/open-r1/OpenR1-Math-220k">OpenR1-Math-220k</a>, <a href="https://huggingface.co/datasets/meta-math/MetaMathQA">MetaMathQA</a> and <a href="https://huggingface.co/datasets/KbsdJames/Omni-MATH">Omni-MATH</a>, and downsample openwebmath to maintain balance class.</li>
<li><strong>Red Pajama Ranker</strong>: We use <a href="https://arxiv.org/abs/2411.12372">RedPajamas’s fastText classifier</a>, which provides signals if a text is similar to content in websites referenced by Wikipedia.</li>
<li><strong>Educational Value Ranker</strong>: Inspired by Textbooks are All You Need, we use an open source <a href="https://huggingface.co/blog/kenhktsui/edu-value-classifier-cpu">educational value classifier</a> to recall content with high educational value from the web. Its training data is constructed by employing Phi-3-mini-128k-instruct to annotate MiniPile with educational value.</li>
<li><strong>Limitations.</strong> At present, our rankers are mainly English based and do not rank well non-English text.
The ranking uses an ensemble method to assess the quality of web documents. This approach combines multiple scoring metrics to determine an overall quality score for each document. Notably, we rank web based documents including synthetic documents associated with web data such as MAGACorpus and nemotron-cc,  and do not rank documents from curated sources such as PG-19, The Stack v1, Wikipedia, Stack Exchange, etc., recognizing their established quality and relevance. We use an average score of High Quality Content Score, the Educational Score and Math score to create a Quality score. For high quality documents, our threshold is 0.3. Additionally for Math documents, we also consider documents that might fall below 0.3, but has a math score about 0.8.</li>
</ul>
<h3 id="how-do-we-filter-curated-data">How Do We Filter Curated Data?</h3>
<p>While curated data such as code data from the Stack v1 and Wikipedia are generally of medium to high quality, we perform further processing to improve the quality of the data. Since we multiple sources for the same data (e.g., Stackexchange from both TxT360 and RedPajama v1), we perform a deduplication within subsets. For all datasets, we filter documents that have  high proportions obscene or adult content and content involving minors and sexual abuse. We found that some documents include base64 encoded text which can confuse models, and thus we filtered out these documents.  For Wikipedia based documents, we filtered documents that are mainly about films, sporting events, and biographies of living persons. This was inspired by filtering techniques in <a href="https://arxiv.org/abs/2404.14219">Phi-3</a>.</p>
<h3 id="our-position-for-using-governmental-works">Our Position For Using Governmental Works</h3>
<p>Our ethical and legal reasoning for using government web content—sourced from Common Crawl-related datasets—is as follows:</p>
<ul>
<li><strong>Public Purpose Alignment</strong>: The content created by governments is normally meant to be shared with the public, and by using the data for training we are assisting this purpose.</li>
<li><strong>Purpose of Use</strong>: From a legal perspective, the government works are being redistributed as part of an open source, no-fee dataset to be used to create models are less likely to be copyright violating. This purpose is clearly not to compete with the government’s own usage.</li>
<li><strong>Effect on Potential Market</strong>: We also think it is more likely to be fair use because the use of government website content is unlikely to have an effect on the potential market for the government’s website content because the government is unlikely to be making commercial use to compete with the content as the government is unlikely making commercial use.</li>
<li><strong>Nature of the Content</strong>: The nature of the content is mostly public announcements, content of public interest, governmental functions or the like. Again, we believe there is strong public policy interest for fair use of this type of information.</li>
<li><strong>Amount Used</strong>: While we use all or almost all of the content of the government website, the amount of usage is not determinative of fair-use or not fair-use.</li>
<li><strong>Federal vs. Non-Federal Works</strong>: Lastly, US works created by the federal governments are generally not copyrightable. However, we recognize that this is not the case for other foreign governmental works, or non-federal works.</li>
</ul>
<p>For these reasons, we believe using government website data is lower copyright risk. But, to minimize the risk further such as the potential inclusion of third party copyrighted works on government web-pages, we have included keyword filters such as “All Rights Reserved”, “Copyright ©”, etc. to further filter out government web pages that have these terms.</p>
<p>With that said, we do not and cannot guarantee that even with rigorous provenance tracking and standard filtering, that there is no copyright, so we recommend anyone who uses our datasets to consult their own attorney in their jurisdiction.</p>
<p>This is an evolving blog, so check back in from time to time to get updates and welcome to our journey!</p>
<h2 id="citation">Citation</h2>
<pre class="astro-code github-dark" style="background-color:#24292e;color:#e1e4e8; overflow-x: auto;" tabindex="0" data-language="bibtex"><code><span class="line"><span style="color:#F97583">@misc</span><span style="color:#E1E4E8">{</span><span style="color:#B392F0">mixturevitae_2025</span><span style="color:#E1E4E8">,</span></span>
<span class="line"><span style="color:#79B8FF">  author</span><span style="color:#E1E4E8">       = </span><span style="color:#9ECBFF">{</span><span style="color:#E1E4E8">Huu Nguyen, Harsh Raj, Ken Tsui, Diganta Misra, Victor May, Vu Minh Chien</span><span style="color:#9ECBFF">}</span><span style="color:#E1E4E8">,</span></span>
<span class="line"><span style="color:#79B8FF">  title</span><span style="color:#E1E4E8">        = </span><span style="color:#9ECBFF">{</span><span style="color:#E1E4E8">MixtureVitae: A Permissive, High-Performance, Open-Access Pretraining Dataset</span><span style="color:#9ECBFF">}</span><span style="color:#E1E4E8">,</span></span>
<span class="line"><span style="color:#79B8FF">  howpublished</span><span style="color:#E1E4E8"> = </span><span style="color:#9ECBFF">{</span><span style="color:#E1E4E8">https://aurora-lm.github.io/posts/mixturevitae</span><span style="color:#9ECBFF">}</span><span style="color:#E1E4E8">,</span></span>
<span class="line"><span style="color:#79B8FF">  note</span><span style="color:#E1E4E8">         = </span><span style="color:#9ECBFF">{</span><span style="color:#E1E4E8">Accessed: 2025-04-12</span><span style="color:#9ECBFF">}</span><span style="color:#E1E4E8">,</span></span>
<span class="line"><span style="color:#79B8FF">  year</span><span style="color:#E1E4E8">         = </span><span style="color:#9ECBFF">{</span><span style="color:#E1E4E8">2025</span><span style="color:#9ECBFF">}</span></span>
<span class="line"><span style="color:#E1E4E8">}</span></span></code></pre> </div> <div class="prose-a:no-underline"> <span class="mb-2 mr-2 inline-block rounded-full bg-neutral-200 px-3 py-1 text-sm hover:bg-neutral-500 dark:bg-neutral-600"> <a href="/tags/Pre-Training/1/">Pre-Training</a> </span><span class="mb-2 mr-2 inline-block rounded-full bg-neutral-200 px-3 py-1 text-sm hover:bg-neutral-500 dark:bg-neutral-600"> <a href="/tags/Permissive-Data/1/">Permissive-Data</a> </span> </div> <div class="flex justify-between"> <small>Publish on <span>2025-04-12</span>，Update on <span>2025-04-12</span></small> </div> </article> <div class="mt-4"> <div class="grid grid-cols-1 gap-4 md:grid-cols-3"> <div class="relative mb-4 overflow-hidden rounded-xl bg-white transition-transform duration-500 hover:-translate-y-1 hover:scale-105 dark:bg-neutral-900"> <a href="/posts/about-us/"> <picture> <source srcset="https://raw.githubusercontent.com/aurora-lm/aurora-lm.github.io/main/assets/images/about_us/aurora-lm-logo.png 392w, https://raw.githubusercontent.com/aurora-lm/aurora-lm.github.io/main/assets/images/about_us/aurora-lm-logo.png 700w, https://raw.githubusercontent.com/aurora-lm/aurora-lm.github.io/main/assets/images/about_us/aurora-lm-logo.png 980w, https://raw.githubusercontent.com/aurora-lm/aurora-lm.github.io/main/assets/images/about_us/aurora-lm-logo.png 1960w" type="image/avif" sizes="(max-width: 360px) 392px, 
           (max-width: 720px) 700px, 
           (max-width: 1600px) 980px, 
           1960px">  <img src="https://raw.githubusercontent.com/aurora-lm/aurora-lm.github.io/main/assets/images/about_us/aurora-lm-logo.png" srcset="https://raw.githubusercontent.com/aurora-lm/aurora-lm.github.io/main/assets/images/about_us/aurora-lm-logo.png 392w, https://raw.githubusercontent.com/aurora-lm/aurora-lm.github.io/main/assets/images/about_us/aurora-lm-logo.png 700w, https://raw.githubusercontent.com/aurora-lm/aurora-lm.github.io/main/assets/images/about_us/aurora-lm-logo.png 980w, https://raw.githubusercontent.com/aurora-lm/aurora-lm.github.io/main/assets/images/about_us/aurora-lm-logo.png 1960w" alt="About Us" sizes="(max-width: 360px) 392px, 
           (max-width: 720px) 700px, 
           (max-width: 1600px) 980px, 
           1960px" width="1024" height="1024" loading="lazy" decoding="async" class="mx-auto w-full max-w-full rounded-lg"> </picture> <div class="absolute bottom-0 end-0 start-0 bg-gradient-to-t p-4 md:p-5"> <div class="mt-16 flex items-center gap-4 text-xs text-white"> <span>Aurora-M2</span> <span>2025-01-01</span> </div> <h2 class="mt-2 text-lg font-bold text-white">About Us</h2> </div> </a> </div> </div> </div> </main>  </main> <footer class="mt-auto w-full max-w-[85rem] py-10 mx-auto"> <nav class="mx-auto w-full max-w-[85rem] px-4" aria-label="Footer"> <div class="flex flex-col items-center sm:flex-row sm:justify-between"> <div id="navbar-alignment" class="internal-links sm:order-2"> <div class="mt-2 flex flex-row gap-5 sm:mt-0 sm:flex-row sm:items-center sm:ps-5"> <a href="https://www.ontocord.ai/" class="inline-flex gap-x-2 text-sm text-neutral-500 hover:text-neutral-800 dark:text-neutral-500 dark:hover:text-neutral-200"> OntocordAI </a> </div> </div> <div class="mt-2 flex flex-wrap gap-2 sm:order-3 sm:mb-0 sm:gap-0"> <button type="button" class="relative inline-flex h-12 w-12 items-center gap-x-2 bg-white px-4 py-3 text-neutral-500 hover:text-neutral-800 disabled:pointer-events-none disabled:opacity-50  dark:text-neutral-500 dark:hover:text-neutral-200 dark:bg-neutral-900 dark:hover:bg-neutral-900"> <a href="https://x.com/ontocord" class="absolute inset-0 z-10" aria-label="Twitter"></a> <svg width="1em" height="1em" class="icon-base" data-icon="tabler:brand-twitter">   <symbol id="ai:tabler:brand-twitter" viewBox="0 0 24 24"><path fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M22 4.01c-1 .49-1.98.689-3 .99c-1.121-1.265-2.783-1.335-4.38-.737S11.977 6.323 12 8v1c-3.245.083-6.135-1.395-8-4c0 0-4.182 7.433 4 11c-1.872 1.247-3.739 2.088-6 2c3.308 1.803 6.913 2.423 10.034 1.517c3.58-1.04 6.522-3.723 7.651-7.742a13.8 13.8 0 0 0 .497-3.753c0-.249 1.51-2.772 1.818-4.013z"/></symbol><use href="#ai:tabler:brand-twitter"></use>  </svg> </button><button type="button" class="relative inline-flex h-12 w-12 items-center gap-x-2 bg-white px-4 py-3 text-neutral-500 hover:text-neutral-800 disabled:pointer-events-none disabled:opacity-50  dark:text-neutral-500 dark:hover:text-neutral-200 dark:bg-neutral-900 dark:hover:bg-neutral-900"> <a href="https://github.com/aurora-lm" class="absolute inset-0 z-10" aria-label="GitHub"></a> <svg width="1em" height="1em" class="icon-base" data-icon="tabler:brand-github">   <symbol id="ai:tabler:brand-github" viewBox="0 0 24 24"><path fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 19c-4.3 1.4-4.3-2.5-6-3m12 5v-3.5c0-1 .1-1.4-.5-2c2.8-.3 5.5-1.4 5.5-6a4.6 4.6 0 0 0-1.3-3.2a4.2 4.2 0 0 0-.1-3.2s-1.1-.3-3.5 1.3a12.3 12.3 0 0 0-6.2 0C6.5 2.8 5.4 3.1 5.4 3.1a4.2 4.2 0 0 0-.1 3.2A4.6 4.6 0 0 0 4 9.5c0 4.6 2.7 5.7 5.5 6c-.6.6-.6 1.2-.5 2V21"/></symbol><use href="#ai:tabler:brand-github"></use>  </svg> </button><button type="button" class="relative inline-flex h-12 w-12 items-center gap-x-2 bg-white px-4 py-3 text-neutral-500 hover:text-neutral-800 disabled:pointer-events-none disabled:opacity-50  dark:text-neutral-500 dark:hover:text-neutral-200 dark:bg-neutral-900 dark:hover:bg-neutral-900"> <a href="https://discord.gg/RBAjeWSA" class="absolute inset-0 z-10" aria-label="Discord"></a> <svg width="1em" height="1em" class="icon-base" data-icon="tabler:brand-discord">   <symbol id="ai:tabler:brand-discord" viewBox="0 0 24 24"><g fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2"><path d="M8 12a1 1 0 1 0 2 0a1 1 0 0 0-2 0m6 0a1 1 0 1 0 2 0a1 1 0 0 0-2 0"/><path d="M15.5 17c0 1 1.5 3 2 3c1.5 0 2.833-1.667 3.5-3c.667-1.667.5-5.833-1.5-11.5c-1.457-1.015-3-1.34-4.5-1.5l-.972 1.923a11.9 11.9 0 0 0-4.053 0L9 4c-1.5.16-3.043.485-4.5 1.5c-2 5.667-2.167 9.833-1.5 11.5c.667 1.333 2 3 3.5 3c.5 0 2-2 2-3"/><path d="M7 16.5c3.5 1 6.5 1 10 0"/></g></symbol><use href="#ai:tabler:brand-discord"></use>  </svg> </button> </div> <div class="mt-2 sm:order-1 sm:mb-0"> <a class="flex-none text-sm text-neutral-500 hover:text-neutral-800 dark:text-neutral-500 dark:hover:text-neutral-200" href="/" aria-label="Brand">Aurora-M2 &copy; 2025</a> </div> </div> </nav> </footer> </body></html>