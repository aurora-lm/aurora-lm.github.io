<?xml version="1.0" encoding="UTF-8"?><rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/"><channel><title>NovaSky</title><description>Next-generation Open Vision and AI @ Berkeley Sky Computing Lab</description><link>https://aurora-lm.github.io/</link><language>en-US</language><item><title>Dummy</title><link>https://aurora-lm.github.io/posts/Dummy/</link><guid isPermaLink="true">https://aurora-lm.github.io/posts/Dummy/</guid><description>Yet to come</description><pubDate>Fri, 21 Feb 2025 00:00:00 GMT</pubDate><content:encoded># Dummy Mixture Vitae Post

This is a sample post created to fulfill the content schema for Astro&apos;s content collections. Replace this text with your actual content when ready.</content:encoded></item><item><title>Home</title><link>https://aurora-lm.github.io/posts/home/</link><guid isPermaLink="true">https://aurora-lm.github.io/posts/home/</guid><description>Home Page</description><pubDate>Wed, 01 Jan 2025 00:00:00 GMT</pubDate><content:encoded>AuroraLM is a collaborative effort led by OntocordAI to create completely permissive AI stack for building Multimodal lanrge Language Models. Create a model and dataset aligned with the laws of nations and policies. Developing such a model opens doors for research into creating AI systems that comply with the laws and policies of specific nations, companies, and regions. This aligns with OntocordAI&apos;s mission to develop lawful and policy-compliant models.
As part of our commitment to openness, we plan to open-source the entire training pipeline and experimental processâ€”including data synthesis and the evolving methodologies we explore in model training.

### Team

&lt;table style=&quot;table-layout: fixed; width: 100%; border-collapse: collapse;&quot;&gt;
  &lt;tr&gt;
    &lt;td style=&quot;width: 25%; text-align: center; vertical-align: middle; height: 150px;&quot;&gt;
      &lt;img 
        src=&quot;https://raw.githubusercontent.com/aurora-lm/aurora-lm.github.io/main/assets/home/huu.jpeg&quot; 
        width=&quot;100&quot; 
        style=&quot;display: block; margin: 0 auto; border-radius:50%;&quot; 
      /&gt;&lt;br&gt;
      &lt;strong&gt;&lt;a href=&quot;https://www.linkedin.com/in/huu-ai-machine-learning/&quot;&gt;Huu Nguyen&lt;/a&gt;&lt;/strong&gt;&lt;br&gt;
      &lt;em&gt;Data Lead&lt;/em&gt;
    &lt;/td&gt;
    &lt;td style=&quot;width: 25%; text-align: center; vertical-align: middle; height: 150px;&quot;&gt;
      &lt;img 
        src=&quot;https://raw.githubusercontent.com/aurora-lm/aurora-lm.github.io/main/assets/home/harsh.jpeg&quot; 
        width=&quot;100&quot; 
        style=&quot;display: block; margin: 0 auto; border-radius:50%;&quot; 
      /&gt;&lt;br&gt;
      &lt;strong&gt;&lt;a href=&quot;https://harshraj-172.github.io/&quot;&gt;Harsh Raj&lt;/a&gt;&lt;/strong&gt;&lt;br&gt;
      &lt;em&gt;Training Lead&lt;/em&gt;
    &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tr&gt;
&lt;/table&gt;






&lt;!-- ### Acknowledgement
Members are funded by the [Berkeley Sky Computing ](https://sky.cs.berkeley.edu/). The compute resources are also generously supported by [Lambda Labs](https://lambdalabs.com/) and [Anyscale](https://www.anyscale.com/). --&gt;

### Contact
X: [@Ontocord](https://x.com/Ontocord)

Email: huu@ontocord.ai

Huggingface: [ontocord](https://huggingface.co/ontocord)

Github: [ontocord](https://github.com/ontocord)</content:encoded></item></channel></rss>